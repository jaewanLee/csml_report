# BTC 'Sell' Signal Prediction - Ablation Study Plan

## üéØ Project Overview

**Goal:** Systematic Ablation Study to identify optimal Multi-Timeframe (MTF) and Historical Lag feature combinations for BTC 'Sell' signal prediction.

**Research Questions:**
- **RQ1 (Current timepoint):** What is the optimal MTF combination when expanding H4‚ÜíD1‚ÜíW1?
- **RQ2 (Historical timepoint):** Do systematic historical lag features improve prediction?

**Architecture:** Stacking Ensemble (XGBoost + Random Forest + Logistic Regression) + Meta-model for fair comparison across all experiments.

---

## üìã Implementation Steps

### **Step 1: Data Collection**
**Duration:** 1-2 days  
**Objective:** Collect comprehensive BTC historical data for all timeframes

#### Tasks:
- [x] **1.1** Set up ccxt library and configure exchange connections
- [x] **1.2** Collect OHLCV data for multiple timeframes (H4, D1, W1, **M1**)
- [x] **1.3** Data period: 2020-03-01 to 2025-10-19 (fixed end date for reproducibility) with training: 2020-05-12 to 2024-04-20, test: 2024-04-20 to 2025-10-19
- [x] **1.4** Implement data validation and quality checks
- [x] **1.5** Store data in Parquet format (better compression and performance)
- [x] **1.6** Create data collection pipeline with error handling and logging

#### Deliverables:
- [x] Raw BTC OHLCV datasets for all timeframes (Parquet format)
- [x] Data quality report
- [x] Modular data collection pipeline script

---

### **Step 2: Feature Engineering & Experiment Sets** üîÑ **REVISITING - PERFORMANCE ISSUES**
**Duration:** 3-4 days  
**Objective:** Create systematic Ablation Study feature sets to answer research questions

#### **üö® CRITICAL PERFORMANCE ISSUE:**
- **XGBoost Test F1-Score:** ~20% (extremely poor performance)
- **Status:** Step 3 cancelled, returning to Step 2 for fundamental fixes
- **Priority:** Identify and fix root causes before proceeding

#### Tasks:
- [x] **2.1** Data exploration and threshold analysis:
  - ‚úÖ Analyzed actual 4H data to determine optimal threshold
  - ‚úÖ Counted Sell labels for different thresholds (-10%, -15%, -20%)
  - ‚úÖ **DECISION: Selected -15% threshold** (see results.md for detailed analysis)
  - ‚úÖ Validated data quality and completeness
- [ ] **2.1.1** **URGENT: Performance Analysis & Root Cause Investigation:**
  - [ ] **Target Variable Validation:**
    - [ ] Verify -15% threshold logic is correct
    - [ ] Test different thresholds (-5%, -10%, -20%, -25%)
    - [ ] Analyze label distribution and temporal patterns
    - [ ] Check for data leakage in target calculation
  - [ ] **Feature Quality Analysis:**
    - [ ] Validate technical indicators calculations
    - [ ] Check for missing values or outliers
    - [ ] Analyze feature correlations and distributions
    - [ ] Test feature importance with simple models
  - [ ] **Data Quality Deep Dive:**
    - [ ] Verify temporal alignment across timeframes
    - [ ] Check for data gaps or inconsistencies
    - [ ] Validate OHLCV data integrity
    - [ ] Test data leakage prevention measures
  - [ ] **Baseline Model Testing:**
    - [ ] Test simple logistic regression on A0
    - [ ] Test random forest on A0
    - [ ] Compare different class balancing strategies
    - [ ] Validate cross-validation setup
- [x] **2.2** Calculate technical indicators for ALL timeframes (H4, D1, W1):
  - ‚úÖ RSI (14-period) - based on CLOSE prices
  - ‚úÖ MACD (12,26,9) - based on CLOSE prices
  - ‚úÖ **Moving Averages (timeframe-specific):**
    - ‚úÖ **H4:** (7,14,20,60,120) - all periods available
    - ‚úÖ **D1:** (7,14,20,60,120) - all periods available  
    - ‚úÖ **W1:** (7,14,20,60,120) - all periods available  
  - ‚úÖ Ichimoku Cloud components - based on CLOSE prices
  - ‚úÖ OHLCV derivatives - all calculations use CLOSE prices
  - ‚úÖ **CRITICAL FIX: Feature Normalization:**
    - ‚úÖ **Problem Identified:** Models were memorizing absolute price values instead of learning patterns
    - ‚úÖ **Solution:** Normalize all features to relative values using `normalize_all_features()`
    - ‚úÖ **Implementation:** Convert OHLCV, MA, Ichimoku to relative/percentage changes
    - ‚úÖ **Cleanup:** Remove absolute value features using `remove_absolute_value_features()`
    - ‚úÖ **Normalized Features Created:**
      - **Moving Averages:** `MA_{period}_norm` (close/MA - 1), `MA_{short}_{long}_norm` (MA ratios)
      - **Ichimoku:** `close_vs_{line}_pct` (close vs lines), `conversion_vs_baseline_pct`, `span_A_vs_span_B_pct`
      - **Candle Features:** `candle_body_pct`, `high_wick_pct`, `low_wick_pct`, `range_pct`
      - **Volume Features:** `volume_vs_MA_{period}_pct`, `volume_change_pct`
      - **Technical Indicators:** RSI, MACD (unchanged - already normalized)
- [x] **2.3** Create Ablation Study feature sets (RQ1 - MTF contribution):
  - ‚úÖ **A0 (Baseline):** H4 indicators (current time t only) - normalized features
  - ‚úÖ **A1 (MTF-1):** A0 + D1 indicators (current time t only) - normalized features
  - ‚úÖ **A2 (MTF-2):** A1 + W1 indicators (current time t only) - normalized features
  - ‚úÖ **A3 (MTF-3):** A2 + lag features (H4+D1+W1 historical data) - normalized features **MAJOR RESTRUCTURE: Removed M1 timeframe, A3 now includes lag features**
- [x] **2.4** Create lag features (RQ2 - Historical contribution):
  - ‚úÖ H4 Lags: t-1 ~ t-6 (normalized features)
  - ‚úÖ D1 Lags: t-1 ~ t-7 (normalized features)
  - ‚úÖ W1 Lags: t-1 ~ t-4 (normalized features)
  - ‚ùå **M1 Lags: REMOVED** - M1 timeframe completely eliminated
- [x] **2.5** **SIMPLIFIED FEATURE STRUCTURE:**
  - ‚úÖ **A0:** H4 only (current time t) - normalized features
  - ‚úÖ **A1:** H4 + D1 (current time t) - normalized features  
  - ‚úÖ **A2:** H4 + D1 + W1 (current time t) - normalized features
  - ‚úÖ **A3:** H4 + D1 + W1 + Historical Lags - normalized features **FINAL FEATURE SET**
- [x] **2.6** Target variable creation (Binary: Sell vs Rest):
  - ‚úÖ **OPTIMIZATION COMPLETED: Systematic analysis of 32 configurations**
  - ‚úÖ **SELECTED CONFIGURATION: Window 50, Upper +10%, Lower -12%**
  - ‚úÖ **Rationale**: Optimal balance of risk management (-12% threshold), signal frequency (13.29%), and temporal consistency (63.1%)
  - ‚úÖ **Analysis Process**: 
    - Phase 1: Enhanced monthly distribution comparison (16 configurations)
    - Phase 2: Large window analysis (16 configurations) 
    - Phase 3: Specific combination validation
  - ‚úÖ **Final Results: 11,737 records, 1,560 SELL (13.29%), 10,177 REST (86.71%)**
  - ‚úÖ **Monthly Consistency**: 63.1% (41/65 months with SELL signals)
  - ‚úÖ **Risk Management**: -12% threshold provides adequate downside protection
  - ‚úÖ **Signal Frequency**: 13.29% SELL ratio optimal for model training
  - ‚úÖ **Documentation**: Complete optimization report saved to `target_variable_optimization_report.md`
- [x] **2.7** Data leakage prevention:
  - ‚úÖ Use completed candles only (e.g., 2020-01-01 00:00-04:00 candle available at 04:01)
  - ‚úÖ No future data usage in feature engineering
  - ‚úÖ Proper temporal alignment for multi-timeframe features
- [x] **2.8** Data split:
  - ‚úÖ Train/Validation: 2020-05-12 to 2024-04-20 (split using TimeSeriesSplit)
  - ‚úÖ Final Test: 2024-04-20 to 2025-09-19 (30-day buffer for label creation)
  - ‚úÖ Label Buffer: 2025-09-20 to 2025-10-19 (for final test labels)
  - ‚úÖ Buffer Period: 2020-03-01 to 2020-05-11 (for M1 lag features t-1, t-2)
  - ‚úÖ Ensure temporal order: past ‚Üí future prediction
  - ‚úÖ No shuffle: maintain time series data order

#### Deliverables:
- ‚úÖ 4 separate feature files: A0.parquet, A1.parquet, A2.parquet, A3.parquet **SIMPLIFIED: Removed A4, A3 now includes lag features**
- ‚úÖ Target variable file: y.parquet
- ‚úÖ Data exploration report with threshold analysis
- ‚úÖ Feature importance analysis
- ‚úÖ **CRITICAL: Normalized feature sets** - All features converted to relative values
- ‚úÖ **CRITICAL: Absolute value features removed** - Prevented model memorization of price values

#### **üìä DETAILED FEATURE BREAKDOWN BY EXPERIMENT SET:**

**A0 (H4 Only - Baseline):**
- **Technical Indicators:** RSI_14, MACD_line, MACD_signal, MACD_histogram
- **Moving Averages (Normalized):** MA_7_norm, MA_14_norm, MA_20_norm, MA_60_norm, MA_120_norm
- **MA Ratios:** MA_7_14_norm, MA_7_20_norm, MA_7_60_norm, MA_7_120_norm, MA_14_20_norm, MA_14_60_norm, MA_14_120_norm, MA_20_60_norm, MA_20_120_norm, MA_60_120_norm
- **Ichimoku (Normalized):** close_vs_conversion_line_pct, close_vs_baseline_pct, close_vs_leading_span_A_pct, close_vs_leading_span_B_pct, close_vs_lagging_span_pct, conversion_vs_baseline_pct, span_A_vs_span_B_pct
- **Candle Features:** candle_body_pct, high_wick_pct, low_wick_pct, range_pct
- **Volume Features:** volume_vs_MA_20_pct, volume_change_pct
- **Total Features:** ~19 normalized features

**A1 (H4 + D1):**
- **All A0 features** (H4 timeframe)
- **Plus D1 features:** Same structure as A0 but for D1 timeframe
- **Total Features:** ~38 normalized features

**A2 (H4 + D1 + W1):**
- **All A1 features** (H4 + D1 timeframes)
- **Plus W1 features:** Same structure as A0 but for W1 timeframe
- **Total Features:** ~56 normalized features

**A3 (H4 + D1 + W1 + Historical Lags):**
- **All A2 features** (H4 + D1 + W1 timeframes)
- **Plus Historical Lags:**
  - **H4 Lags (t-1 to t-6):** All A0 features with lag suffixes
  - **D1 Lags (t-1 to t-7):** All D1 features with lag suffixes  
  - **W1 Lags (t-1 to t-4):** All W1 features with lag suffixes
- **Total Features:** ~200+ normalized features (exact count depends on lag combinations)

#### **üîß FEATURE NORMALIZATION DETAILS:**

**Moving Average Normalization:**
- `MA_{period}_norm = (close / MA_{period}) - 1` - Price vs MA relative position
- `MA_{short}_{long}_norm = (MA_{short} / MA_{long}) - 1` - MA crossover signals

**Ichimoku Normalization:**
- `close_vs_{line}_pct = (close / {line}) - 1` - Price position relative to Ichimoku lines
- `conversion_vs_baseline_pct = (conversion_line / baseline) - 1` - Conversion vs Baseline signal
- `span_A_vs_span_B_pct = (leading_span_A / leading_span_B) - 1` - Cloud thickness indicator

**Candle Feature Normalization:**
- `candle_body_pct = (close - open) / open` - Candle body strength
- `high_wick_pct = (high - max(open,close)) / close` - Upper wick length
- `low_wick_pct = (min(open,close) - low) / close` - Lower wick length
- `range_pct = (high - low) / low` - Total candle range

**Volume Feature Normalization:**
- `volume_vs_MA_{period}_pct = (volume / volume_MA_{period}) - 1` - Volume vs average
- `volume_change_pct = volume.pct_change()` - Volume momentum

#### **Key Modifications Made During Implementation:**

1. **M1 Timeframe Complete Removal:**
   - **Issue:** M1 data insufficient for reliable indicators and added complexity
   - **Solution:** Completely eliminated M1 timeframe from all feature sets
   - **Impact:** Simplified feature structure, A3 now includes lag features instead of A4

2. **Feature Normalization Critical Fix:**
   - **Issue:** Models were memorizing absolute price values instead of learning patterns
   - **Solution:** Implemented `normalize_all_features()` to convert all features to relative values
   - **Implementation:** OHLCV, MA, Ichimoku converted to percentage changes
   - **Cleanup:** Used `remove_absolute_value_features()` to remove absolute value columns
   - **Result:** Models now learn patterns instead of memorizing prices

3. **Target Variable Logic Bug:**
   - **Issue:** Initial implementation used `idxmax()` which finds last occurrence, not first
   - **Solution:** Implemented direct assignment approach with single loop for efficiency
   - **Result:** Correct class distribution (22.9% SELL, 77.1% REST)

4. **Simplified Feature Structure:**
   - **Issue:** Complex A4 feature set with too many dimensions
   - **Solution:** Restructured to A0-A3 with A3 including historical lags
   - **Result:** More manageable feature sets with better interpretability

5. **Data Validation:**
   - **Issue:** Missing values in M1 indicators due to insufficient historical data
   - **Solution:** Removed M1 timeframe entirely, focused on H4, D1, W1
   - **Result:** Clean feature sets with no missing values and normalized data


---

### **Step 3: Architecture & Environment Setup** üîÑ **READY TO RESUME - PERFORMANCE FIXES APPLIED**
**Duration:** 2-3 days  
**Objective:** Build modular codebase for systematic experiment execution

#### **‚úÖ PERFORMANCE ISSUES RESOLVED:**
- **Previous Issue:** XGBoost Test Performance ~20% F1-Score (extremely poor)
- **Root Cause Identified:** Models memorizing absolute price values instead of learning patterns
- **Solution Applied:** Feature normalization and M1 timeframe removal
- **Status:** Ready to resume Step 3 implementation with improved feature sets

#### Tasks:
- [x] **3.1** Conda environment setup (Python 3.13, requirements.txt)
- [x] **3.2** Create modular codebase structure for ablation study experiments:
  ```
  btc_prediction/
  ‚îú‚îÄ‚îÄ config/
  ‚îÇ   ‚îú‚îÄ‚îÄ settings.py               # ‚úÖ Data paths, constants, temporal split boundaries
  ‚îÇ   ‚îî‚îÄ‚îÄ model_params.py           # ‚úÖ Hyperparameter grids for all models
  ‚îú‚îÄ‚îÄ utils/                        # ‚úÖ COMPLETED: Shared utilities
  ‚îÇ   ‚îú‚îÄ‚îÄ data_utils.py             # ‚úÖ Data loading, temporal split, validation
  ‚îÇ   ‚îú‚îÄ‚îÄ cv_utils.py               # ‚úÖ TimeSeriesSplit utilities (n_splits=5)
  ‚îÇ   ‚îî‚îÄ‚îÄ evaluation_utils.py       # ‚úÖ Metrics calculation and comparison
  ‚îú‚îÄ‚îÄ features/                     # ‚úÖ COMPLETED: Feature sets from Step 2
  ‚îÇ   ‚îú‚îÄ‚îÄ A0.parquet               # ‚úÖ 19 features (H4 only)
  ‚îÇ   ‚îú‚îÄ‚îÄ A1.parquet               # ‚úÖ 38 features (H4 + D1)
  ‚îÇ   ‚îú‚îÄ‚îÄ A2.parquet               # ‚úÖ 56 features (H4 + D1 + W1)
  ‚îÇ   ‚îú‚îÄ‚îÄ A3.parquet               # ‚úÖ 67 features (H4 + D1 + W1 + M1)
  ‚îÇ   ‚îú‚îÄ‚îÄ A4.parquet               # ‚úÖ 416 features (A3 + historical lags)
  ‚îÇ   ‚îî‚îÄ‚îÄ y.parquet                # ‚úÖ 11,737 records (target variable)
  ‚îî‚îÄ‚îÄ notebooks/                    # ‚úÖ COMPLETED: Data processing notebooks
      ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb # ‚úÖ COMPLETED
      ‚îî‚îÄ‚îÄ 02_feature_engineering.ipynb # ‚úÖ COMPLETED
  ```
- [x] **3.3** **BASIC XGBOOST TEST PERFORMED:**
  - ‚úÖ Simple XGBoost model tested on A0 features
  - ‚ùå **INITIAL RESULT: ~20% F1-Score (unacceptable)**
  - ‚úÖ **ROOT CAUSE IDENTIFIED: Model memorization of absolute price values**
  - ‚úÖ **SOLUTION APPLIED: Feature normalization and M1 removal**
  - üîÑ **STATUS: Ready to retest with normalized features**

#### **Issues Resolved:**
1. ‚úÖ **Feature Normalization:** All features converted to relative values
2. ‚úÖ **Absolute Value Removal:** Prevented model memorization of prices
3. ‚úÖ **M1 Timeframe Removal:** Simplified feature structure
4. ‚úÖ **Data Quality:** Clean normalized feature sets with no missing values

#### Deliverables:
- ‚úÖ Configuration files (settings.py, model_params.py)
- ‚úÖ Utility functions (data_utils.py, cv_utils.py, evaluation_utils.py)
- ‚úÖ TimeSeriesSplit cross-validation framework (n_splits=5)
- ‚úÖ Data leakage prevention with temporal gap
- ‚ùå **Model implementations CANCELLED due to poor performance**

---

### **Step 4: Ablation Study Experiment Loop** üîÑ **READY TO RESUME - SIMPLIFIED STRUCTURE**
**Duration:** 4-5 days  
**Objective:** Execute systematic experiments to answer research questions

#### **‚úÖ STATUS: READY TO RESUME**
- **Prerequisite:** Step 2 performance issues resolved with feature normalization
- **Current Status:** Ready to proceed with simplified A0-A3 feature structure
- **Next Action:** Implement model classes and run experiments on normalized features

#### Tasks:
- [ ] **4.1** Setup experiment logger:
  - Create `experiment_results.csv` with columns: Experiment_ID, Num_Features, Final_Test_F1, Final_Test_Precision, Final_Test_Recall, etc.
- [ ] **4.2** Main experiment loop - Simplified structure (RQ1 - MTF contribution):
  - **XGBoost:** `python training/xgboost/run_experiment.py --exp_id A0` (H4 only, normalized)
  - **XGBoost:** `python training/xgboost/run_experiment.py --exp_id A1` (H4+D1, normalized)
  - **XGBoost:** `python training/xgboost/run_experiment.py --exp_id A2` (H4+D1+W1, normalized)
  - **XGBoost:** `python training/xgboost/run_experiment.py --exp_id A3` (H4+D1+W1+Lags, normalized)
  - **Random Forest:** `python training/random_forest/run_experiment.py --exp_id A0`
  - **Random Forest:** `python training/random_forest/run_experiment.py --exp_id A1`
  - **Random Forest:** `python training/random_forest/run_experiment.py --exp_id A2`
  - **Random Forest:** `python training/random_forest/run_experiment.py --exp_id A3`
  - **Logistic Regression:** `python training/logistic_regression/run_experiment.py --exp_id A0`
  - **Logistic Regression:** `python training/logistic_regression/run_experiment.py --exp_id A1`
  - **Logistic Regression:** `python training/logistic_regression/run_experiment.py --exp_id A2`
  - **Logistic Regression:** `python training/logistic_regression/run_experiment.py --exp_id A3`
- [ ] **4.3** Checkpoint analysis:
  - Analyze A0~A3 results from experiment_results.csv
  - Validate pipeline is working correctly with normalized features
  - Compare performance across different feature combinations
  - Identify optimal MTF combination for RQ1

#### Deliverables:
- experiment_results.csv with all 4 experiments (A0, A1, A2, A3) using normalized features
- Model artifacts (.pkl) for each experiment
- Performance analysis comparing MTF contributions

---

### **Step 5: Results Analysis & RQ Answers** üîÑ **READY TO RESUME - SIMPLIFIED STRUCTURE**
**Duration:** 1-2 days  
**Objective:** Analyze results and provide data-driven answers to research questions

#### **‚úÖ STATUS: READY TO RESUME**
- **Prerequisite:** Step 4 experiments with normalized features
- **Current Status:** Ready to analyze A0-A3 results
- **Next Action:** Compare MTF contributions and answer research questions

#### Tasks:
- [ ] **5.1** Load and visualize experiment_results.csv
- [ ] **5.2** Answer RQ1 (MTF contribution):
  - Compare A0 vs A1 vs A2 Final_Test_F1 (H4 only vs H4+D1 vs H4+D1+W1)
  - Determine if each timeframe addition helps or adds noise
  - Identify optimal MTF combination from H4, D1, W1 timeframes
- [ ] **5.3** Answer RQ2 (Historical lags contribution):
  - Compare A2 (H4+D1+W1) vs A3 (H4+D1+W1+Lags) Final_Test_F1
  - Assess if historical lag features provide meaningful improvement
  - Analyze which lag periods (t-1 to t-6 for H4, t-1 to t-7 for D1, t-1 to t-4 for W1) are most predictive
- [ ] **5.4** Feature importance analysis:
  - Identify top 20 features from A3 (final feature set)
  - Analyze which timeframes and lags are most important
- [ ] **5.5** Statistical significance testing:
  - Compare performance differences between experiments
  - Validate that improvements are meaningful, not random

#### Deliverables:
- Analysis report answering RQ1 and RQ2
- Performance comparison charts
- Feature importance plots
- Statistical significance test results

---

### **Step 6: Conclusion & Documentation**
**Duration:** 1-2 days  
**Objective:** Finalize results and create comprehensive documentation

#### Tasks:
- [ ] **6.1** Final research results summary
- [ ] **6.2** Compare with baseline models
- [ ] **6.3** Document lessons learned and limitations
- [ ] **6.4** Prepare model deployment guidelines
- [ ] **6.5** Create user documentation
- [ ] **6.6** GitHub repository organization

#### Deliverables:
- Final research results report
- Model deployment package
- Comprehensive documentation
- Lessons learned document

---

## üîß **Critical Implementation Notes**

### **Hyperparameter Tuning Strategy**
- **L0 (XGBoost, Random Forest):** BayesSearchCV with n_iter=50
  - Param spaces: max_depth, learning_rate, n_estimators, scale_pos_weight
- **L0 (Logistic Regression):** GridSearchCV
  - Param grid: C, penalty, solver
- **L1 (Meta-LR):** GridSearchCV on meta-features

### **Tuning ‚Üí Training Workflow**
1. Use BayesSearchCV/GridSearchCV to find `best_params` (NOT `best_estimator`)
2. Create NEW models with `best_params` for meta-feature generation (TimeSeriesSplit loop)
3. Create NEW models with `best_params` for final training (full Train/Val dataset)
4. Manually save: `joblib.dump(model, 'path/to/model.pkl')`

### **TimeSeriesSplit Implementation**
- n_splits=5 baseline (from refine_methods.md)
- Ensure temporal order, no shuffle
- Same split used for tuning and meta-feature generation
- Prevents data leakage

### **Data Leakage Prevention**
- Use completed candles only
- No future data in feature engineering
- Proper temporal alignment for MTF features
- Target calculation: current close ‚Üí future LOW (not future close)

### **Stacking Ensemble Key Points**
- **Never use `best_estimator` directly** - it's trained on CV data
- **Always create fresh models** with `best_params` for each fold
- **Meta-features must be generated** using the same TimeSeriesSplit as tuning
- **Final models trained** on full dataset (2020-2024) for Test Set predictions

---

## üìä Success Metrics

### **Model Performance:**
- **Primary:** F1-Score for 'Sell' class
- **Secondary:** Precision, Recall, ROC-AUC
- **Target:** Final model (A4_Pruned) achieves F1 ‚â• 0.70 on test set

### **Research:**
- **Clear, data-driven answers to RQ1 and RQ2**
- **Statistical Significance:** Performance differences between experiments are meaningful
- **Feature Insights:** Identify which timeframes and lags contribute most

### **Technical:**
- Model training time < 2 hours per experiment
- Prediction latency < 100ms
- Model size < 100MB

---

## üö® Risk Mitigation

### **Data Risks:**
- Missing data handling strategies
- Data quality validation
- Temporal consistency checks

### **Model Risks:**
- Overfitting prevention through proper validation
- Class imbalance handling
- Data leakage prevention

### **Experiment Risks:**
- **Checkpoint at 4.3:** Validate pipeline before proceeding to A4
- **Feature Pruning:** Prevents A4 from being too high-dimensional
- **TimeSeriesSplit:** Prevents overfitting through proper validation
- **Fallback:** If all experiments show low performance, revisit target definition (Step 2.6)

---

## üéØ Next Immediate Action

**‚úÖ READY TO PROCEED: Step 3 Model Implementation**

**Performance Issues Resolved:**
- ‚úÖ Root cause identified: Model memorization of absolute price values
- ‚úÖ Solution applied: Feature normalization and M1 timeframe removal
- ‚úÖ Feature sets restructured: A0-A3 with normalized features
- ‚úÖ Ready to implement model classes and run experiments

**Immediate Priority Tasks:**
- [ ] **3.3** Implement Level 0 model classes:
  - [ ] XGBoost model with Bayesian optimization tuning
  - [ ] Random Forest model with Bayesian optimization tuning
  - [ ] Logistic Regression model with GridSearchCV tuning
- [ ] **3.4** Implement Level 1 meta-model class:
  - [ ] Meta-LR model for stacking ensemble
- [ ] **3.5** Create model-specific experiment scripts:
  - [ ] XGBoost experiment runner
  - [ ] Random Forest experiment runner
  - [ ] Logistic Regression experiment runner
- [ ] **3.6** Test baseline performance:
  - [ ] Run simple XGBoost test on normalized A0 features
  - [ ] Validate performance improvement over previous 20% F1-Score
  - [ ] Ensure acceptable baseline before full experiments

**Success Criteria:**
- Achieve baseline F1-Score > 50% on normalized features
- Implement all model classes and experiment scripts
- Validate pipeline works correctly with A0-A3 feature sets
- Ready to proceed to Step 4 systematic experiments

**Current Status:**
- ‚úÖ Configuration files (settings.py, model_params.py)
- ‚úÖ Utility functions (data_utils.py, cv_utils.py, evaluation_utils.py)
- ‚úÖ TimeSeriesSplit framework with data leakage prevention
- ‚úÖ Temporal split boundaries (TRAIN_END='2024-04-19', TEST_START='2024-04-21')
- ‚úÖ **Normalized feature sets (A0-A3) ready for experiments**
- üîÑ **Ready to implement model classes and run experiments**

The systematic Ablation Study approach will provide clear answers to both research questions through controlled experiments with improved normalized features.

---

## ‚úÖ **CURRENT STATUS - PERFORMANCE ISSUES RESOLVED**

### **Performance Crisis Resolution:**
- **Previous Issue:** XGBoost baseline test performance ~20% F1-Score
- **Root Cause Identified:** Models memorizing absolute price values instead of learning patterns
- **Solution Applied:** Feature normalization and M1 timeframe removal
- **Status:** Ready to proceed with Step 3 model implementation

### **Key Improvements Made:**
1. **Feature Normalization** ‚úÖ
   - All features converted to relative/percentage values
   - Prevented model memorization of absolute prices
   - Models now learn patterns instead of specific values
2. **M1 Timeframe Removal** ‚úÖ
   - Eliminated insufficient M1 data
   - Simplified feature structure to A0-A3
   - A3 now includes historical lags instead of A4
3. **Data Quality Enhancement** ‚úÖ
   - Clean normalized feature sets
   - No missing values or data leakage
   - Proper temporal alignment maintained

### **Success Criteria Achieved:**
- ‚úÖ Root cause identified and resolved
- ‚úÖ Feature normalization implemented
- ‚úÖ Simplified feature structure (A0-A3)
- ‚úÖ Ready to proceed to Step 3 model implementations

---

## ü§î **Need to Discuss Further**

### **Rolling Window Validation as Fallback Strategy**
- **Current Approach:** TimeSeriesSplit(n_splits=5) with expanding window
- **Fallback Consideration:** If results are poor, consider **Rolling Window Validation**
- **Rolling Window Benefits:**
  - **More realistic:** Simulates real-world trading where models are retrained periodically
  - **Market regime adaptation:** Better handles changing market conditions over time
  - **Reduced overfitting:** Prevents models from learning specific temporal patterns
  - **Robust validation:** Tests model performance across different time periods
- **Implementation Strategy:**
  - **If F1 < 0.60 on Test Set:** Implement rolling window validation
  - **Rolling Window Parameters:** 2-year training window, 6-month validation window, 1-month step
  - **Example:** Train on 2020-2022, validate on 2022-2022.5, then train on 2020.5-2022.5, validate on 2022.5-2023, etc.
  - **Meta-feature generation:** Use rolling window for both Level 0 and Level 1 models
- **Decision Criteria:**
  - **Keep TimeSeriesSplit if:** F1 ‚â• 0.60, good generalization across folds
  - **Switch to Rolling Window if:** F1 < 0.60, poor performance on recent data, overfitting detected