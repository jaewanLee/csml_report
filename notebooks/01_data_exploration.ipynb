{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BTC Data Exploration\n",
        "\n",
        "## Overview\n",
        "This notebook explores the collected BTC data from different timeframes (4h, 1d, 1w) to understand:\n",
        "- Data quality and completeness\n",
        "- Price patterns and trends\n",
        "- Volume analysis\n",
        "- Data distribution across timeframes\n",
        "\n",
        "## Data Sources\n",
        "- **4h timeframe**: High-frequency data for detailed analysis\n",
        "- **1d timeframe**: Daily patterns and trends\n",
        "- **1w timeframe**: Weekly macro trends\n",
        "\n",
        "## Objectives\n",
        "1. Load and examine collected data\n",
        "2. Perform basic statistical analysis\n",
        "3. Visualize price and volume patterns\n",
        "4. Identify data quality issues\n",
        "5. Prepare data for feature engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data_dir' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdata_dir\u001b[49m.exists():\n\u001b[32m      2\u001b[39m     files = \u001b[38;5;28mlist\u001b[39m(data_dir.glob(\u001b[33m'\u001b[39m\u001b[33m*.parquet\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParquet files found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'data_dir' is not defined"
          ]
        }
      ],
      "source": [
        "if data_dir.exists():\n",
        "    files = list(data_dir.glob('*.parquet'))\n",
        "    print(f\"Parquet files found: {files}\")\n",
        "    for file in files:\n",
        "        print(f\"  - {file.name}\")\n",
        "else:\n",
        "    print(\"Data directory does not exist!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4h data shape: (12367, 5)\n",
            "1d data shape: (2115, 5)\n",
            "1w data shape: (350, 5)\n",
            "1m data shape: (91, 5)\n"
          ]
        }
      ],
      "source": [
        "# Load data from parquet files\n",
        "data_dir = Path('../data_collection/data')\n",
        "\n",
        "# Load different timeframes\n",
        "data_4h = pd.read_parquet(data_dir / 'btc_4h_20251022.parquet')  # Use actual filename\n",
        "data_1d = pd.read_parquet(data_dir / 'btc_1d_20251022.parquet')\n",
        "data_1w = pd.read_parquet(data_dir / 'btc_1w_20251022.parquet')\n",
        "data_1m = pd.read_parquet(data_dir / 'btc_1M_20251022.parquet')\n",
        "\n",
        "print(f\"4h data shape: {data_4h.shape}\")\n",
        "print(f\"1d data shape: {data_1d.shape}\")\n",
        "print(f\"1w data shape: {data_1w.shape}\")\n",
        "print(f\"1m data shape: {data_1m.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        open     high      low    close        volume\n",
            "timestamp                                                            \n",
            "2020-03-01 00:00:00  8523.61  8675.00  8511.11  8620.36   6058.887982\n",
            "2020-03-01 04:00:00  8620.17  8634.73  8520.58  8541.16   5437.032897\n",
            "2020-03-01 08:00:00  8541.15  8650.00  8518.00  8648.37   5567.314081\n",
            "2020-03-01 12:00:00  8647.42  8750.00  8535.24  8557.80   9813.477149\n",
            "2020-03-01 16:00:00  8557.80  8582.73  8411.00  8542.20  11521.279904\n",
            "                          open       high        low      close      volume\n",
            "timestamp                                                                  \n",
            "2025-10-20 08:00:00  111169.91  111679.25  110608.27  111016.75  3452.86704\n",
            "2025-10-20 12:00:00  111016.75  111705.56  110588.23  111144.55  3006.20504\n",
            "2025-10-20 16:00:00  111144.55  111303.05  109855.83  110803.22  3716.65669\n",
            "2025-10-20 20:00:00  110803.22  111272.00  110418.25  110532.09  1366.18103\n",
            "2025-10-21 00:00:00  110532.09  110532.09  109303.86  109573.21  1729.32008\n",
            "(12361, 5)\n",
            "126199.63\n",
            "3782.13\n"
          ]
        }
      ],
      "source": [
        "print(data_4h.head(5))\n",
        "print(data_4h.tail(5))\n",
        "print(data_4h.shape)\n",
        "print(data_4h[\"high\"].max())\n",
        "print(data_4h[\"low\"].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               open     high      low    close        volume\n",
            "timestamp                                                   \n",
            "2020-03-01  8523.61  8750.00  8411.00  8531.88  43892.201779\n",
            "2020-03-02  8530.30  8965.75  8498.00  8915.24  60401.317730\n",
            "2020-03-03  8911.18  8919.65  8651.00  8760.07  55154.997282\n",
            "2020-03-04  8760.07  8848.29  8660.00  8750.87  38696.482578\n",
            "2020-03-05  8750.99  9159.42  8746.54  9054.68  58201.866355\n",
            "                 open       high        low      close       volume\n",
            "timestamp                                                          \n",
            "2025-10-17  108194.27  109240.00  103528.23  106431.68  37920.66838\n",
            "2025-10-18  106431.68  107499.00  106322.20  107185.01  11123.18766\n",
            "2025-10-19  107185.00  109450.07  106103.36  108642.78  15480.66423\n",
            "2025-10-20  108642.77  111705.56  107402.52  110532.09  19193.44160\n",
            "2025-10-21  110532.09  110532.09  109303.86  109573.21   1729.33018\n",
            "(2061, 5)\n",
            "126199.63\n",
            "3782.13\n"
          ]
        }
      ],
      "source": [
        "print(data_1d.head(5))\n",
        "print(data_1d.tail(5))\n",
        "print(data_1d.shape)\n",
        "print(data_1d[\"high\"].max())\n",
        "print(data_1d[\"low\"].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               open     high      low    close        volume\n",
            "timestamp                                                   \n",
            "2020-03-02  8530.30  9188.00  8000.00  8033.31  3.791971e+05\n",
            "2020-03-09  8034.76  8179.31  3782.13  5361.30  1.224228e+06\n",
            "2020-03-16  5360.33  6900.00  4442.12  5816.19  1.180843e+06\n",
            "2020-03-23  5816.05  6957.96  5688.00  5881.42  7.703808e+05\n",
            "2020-03-30  5880.50  7198.00  5857.76  6772.78  6.647843e+05\n",
            "                 open       high        low      close         volume\n",
            "timestamp                                                            \n",
            "2025-09-22  115232.29  115379.25  108620.07  112163.95   93970.577040\n",
            "2025-09-29  112163.96  125708.42  111560.65  123482.31  124480.098903\n",
            "2025-10-06  123482.32  126199.63  102000.00  114958.80  211576.359223\n",
            "2025-10-13  114958.81  115963.81  103528.23  108642.78  171795.750970\n",
            "2025-10-20  108642.77  111705.56  107402.52  109573.21   20922.776900\n",
            "(295, 5)\n",
            "126199.63\n",
            "3782.13\n"
          ]
        }
      ],
      "source": [
        "print(data_1w.head(5))\n",
        "print(data_1w.tail(5))\n",
        "print(data_1w.shape)\n",
        "print(data_1w[\"high\"].max())\n",
        "print(data_1w[\"low\"].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               open      high      low    close        volume\n",
            "timestamp                                                    \n",
            "2018-04-01  6922.00   9759.82  6430.00  9246.01  1.110964e+06\n",
            "2018-05-01  9246.01  10020.00  7032.95  7485.01  9.144764e+05\n",
            "2018-06-01  7485.01   7786.69  5750.00  6390.07  9.422498e+05\n",
            "2018-07-01  6391.08   8491.77  6070.00  7730.93  1.102510e+06\n",
            "2018-08-01  7735.67   7750.00  5880.00  7011.21  1.408160e+06\n",
            "                 open       high        low      close         volume\n",
            "timestamp                                                            \n",
            "2025-06-01  104591.88  110530.17   98200.00  107146.50  427546.463360\n",
            "2025-07-01  107146.51  123218.00  105100.19  115764.08  484315.651017\n",
            "2025-08-01  115764.07  124474.00  107350.10  108246.35  471366.942936\n",
            "2025-09-01  108246.36  117900.00  107255.00  114048.93  374551.994070\n",
            "2025-10-01  114048.94  126199.63  102000.00  108258.66  536487.098566\n",
            "(91, 5)\n",
            "126199.63\n",
            "3156.26\n"
          ]
        }
      ],
      "source": [
        "print(data_1m.head(5))\n",
        "print(data_1m.tail(5))\n",
        "print(data_1m.shape)\n",
        "print(data_1m[\"high\"].max())\n",
        "print(data_1m[\"low\"].min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 Testing Target Logic with Simple Version\n",
            "==================================================\n",
            "📊 Data loaded: 2146 records\n",
            "📅 Period: 2019-12-08 00:00:00 to 2025-10-22 00:00:00\n",
            "\n",
            "🔄 Calculating labels...\n",
            "   Processing 0/2146 records...\n",
            "   Processing 500/2146 records...\n",
            "   Processing 1000/2146 records...\n",
            "   Processing 1500/2146 records...\n",
            "   Processing 2000/2146 records...\n",
            "\n",
            "📊 Results:\n",
            "   Total labels: 2146\n",
            "   SELL labels: 351 (16.4%)\n",
            "   REST labels: 1795 (83.6%)\n",
            "   Ratio: 0.2:1 (SELL:REST)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def test_target_logic_simple():\n",
        "    \"\"\"Simple test to verify target logic using daily data\"\"\"\n",
        "    \n",
        "    print(\"🧪 Testing Target Logic with Simple Version\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Load daily data\n",
        "    data = pd.read_parquet('../data_collection/data/btc_1d_20251022.parquet')\n",
        "    print(f\"📊 Data loaded: {len(data)} records\")\n",
        "    print(f\"📅 Period: {data.index[0]} to {data.index[-1]}\")\n",
        "    \n",
        "    # Create target variable with simple logic\n",
        "    y_labels = []\n",
        "    \n",
        "    print(\"\\n🔄 Calculating labels...\")\n",
        "    \n",
        "    for i in range(len(data)):\n",
        "        if i % 500 == 0:\n",
        "            print(f\"   Processing {i}/{len(data)} records...\")\n",
        "        \n",
        "        current_close = data.iloc[i]['close']\n",
        "        \n",
        "        # Look ahead 30 days (30 records for daily data)\n",
        "        if i + 30 < len(data):\n",
        "            future_data = data.iloc[i+1:i+31]\n",
        "            \n",
        "            # Check for +5% threshold first\n",
        "            future_highs = future_data['high']\n",
        "            max_future_high = future_highs.max()\n",
        "            price_increase = (max_future_high - current_close) / current_close\n",
        "            \n",
        "            # Check for -15% threshold\n",
        "            future_lows = future_data['low']\n",
        "            min_future_low = future_lows.min()\n",
        "            price_drop = (min_future_low - current_close) / current_close\n",
        "            \n",
        "            # Determine which threshold was reached first\n",
        "            if price_increase >= 0.05 and price_drop <= -0.15:\n",
        "                # Both thresholds reached - need to check which came first\n",
        "                # Find first occurrence of each\n",
        "                for j in range(len(future_data)):\n",
        "                    future_high = future_data.iloc[j]['high']\n",
        "                    future_low = future_data.iloc[j]['low']\n",
        "                    \n",
        "                    if (future_high - current_close) / current_close >= 0.05:\n",
        "                        # +5% reached first\n",
        "                        y_labels.append(0)  # REST\n",
        "                        break\n",
        "                    elif (future_low - current_close) / current_close <= -0.15:\n",
        "                        # -15% reached first\n",
        "                        y_labels.append(1)  # SELL\n",
        "                        break\n",
        "            elif price_increase >= 0.05:\n",
        "                # Only +5% reached\n",
        "                y_labels.append(0)  # REST\n",
        "            elif price_drop <= -0.15:\n",
        "                # Only -15% reached\n",
        "                y_labels.append(1)  # SELL\n",
        "            else:\n",
        "                # Neither threshold reached\n",
        "                y_labels.append(0)  # REST\n",
        "        else:\n",
        "            # Not enough future data\n",
        "            y_labels.append(0)  # REST\n",
        "    \n",
        "    # Convert to numpy array\n",
        "    y_labels = np.array(y_labels)\n",
        "    \n",
        "    # Calculate statistics\n",
        "    total_labels = len(y_labels)\n",
        "    sell_count = np.sum(y_labels)\n",
        "    rest_count = total_labels - sell_count\n",
        "    \n",
        "    print(f\"\\n📊 Results:\")\n",
        "    print(f\"   Total labels: {total_labels}\")\n",
        "    print(f\"   SELL labels: {sell_count} ({sell_count/total_labels*100:.1f}%)\")\n",
        "    print(f\"   REST labels: {rest_count} ({rest_count/total_labels*100:.1f}%)\")\n",
        "    print(f\"   Ratio: {sell_count/rest_count:.1f}:1 (SELL:REST)\")\n",
        "    \n",
        "    return y_labels\n",
        "\n",
        "# Run the test\n",
        "test_labels = test_target_logic_simple()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "csml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
