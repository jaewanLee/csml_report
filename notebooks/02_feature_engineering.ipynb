{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BTC Feature Engineering - CORRECTED APPROACH\n",
        "\n",
        "## Overview\n",
        "This notebook implements the CORRECTED approach: Calculate everything together, split on save.\n",
        "\n",
        "**Key Changes:**\n",
        "1. Load full data (including buffer) for complete calculations\n",
        "2. Calculate all indicators and features on full data\n",
        "3. Create feature sets A0â†’A4 with proper temporal alignment\n",
        "4. Split clean data only at save step\n",
        "\n",
        "**Benefits:**\n",
        "- Complete historical context for all calculations\n",
        "- Proper temporal alignment with full data\n",
        "- No missing data for lag features\n",
        "- Clean final output without buffer data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import talib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "train_start='2020-05-12'\n",
        "test_end='2025-09-19'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Full data loaded (including buffer):\n",
            "  H4: 12368 records (2020-03-01 00:00:00 to 2025-10-22 04:00:00)\n",
            "  D1: 2146 records (2019-12-08 00:00:00 to 2025-10-22 00:00:00)\n",
            "  W1: 350 records (2019-02-11 00:00:00 to 2025-10-20 00:00:00)\n",
            "  M1: 95 records (2017-12-01 00:00:00 to 2025-10-01 00:00:00)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load Full Data (Including Buffer) for Complete Calculations\n",
        "def load_full_data():\n",
        "    \"\"\"Load full data including buffer for complete calculations\"\"\"\n",
        "    \n",
        "    # Load full data\n",
        "    h4_full = pd.read_parquet('../data_collection/data/btc_4h_20251022.parquet')\n",
        "    d1_full = pd.read_parquet('../data_collection/data/btc_1d_20251022.parquet')\n",
        "    w1_full = pd.read_parquet('../data_collection/data/btc_1w_20251022.parquet')\n",
        "    m1_full = pd.read_parquet('../data_collection/data/btc_1M_20251022.parquet')\n",
        "    \n",
        "    # Ensure datetime index\n",
        "    for df in [h4_full, d1_full, w1_full, m1_full]:\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "    \n",
        "    print(f\"ðŸ“Š Full data loaded (including buffer):\")\n",
        "    print(f\"  H4: {len(h4_full)} records ({h4_full.index[0]} to {h4_full.index[-1]})\")\n",
        "    print(f\"  D1: {len(d1_full)} records ({d1_full.index[0]} to {d1_full.index[-1]})\")\n",
        "    print(f\"  W1: {len(w1_full)} records ({w1_full.index[0]} to {w1_full.index[-1]})\")\n",
        "    print(f\"  M1: {len(m1_full)} records ({m1_full.index[0]} to {m1_full.index[-1]})\")\n",
        "    \n",
        "    return h4_full, d1_full, w1_full, m1_full\n",
        "\n",
        "# Load full data for complete calculations\n",
        "h4_full, d1_full, w1_full, m1_full = load_full_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Technical Indicator Functions\n",
        "def extract_ohlcv_features(data):\n",
        "    \"\"\"Extract OHLCV features (5 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    features['open'] = data['open']\n",
        "    features['high'] = data['high']\n",
        "    features['low'] = data['low']\n",
        "    features['close'] = data['close']\n",
        "    features['volume'] = data['volume']\n",
        "    return features\n",
        "\n",
        "def calculate_moving_averages(data, periods=[7, 14, 20, 60, 120]):\n",
        "    \"\"\"Calculate moving averages using CLOSE prices (5 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    for period in periods:\n",
        "        features[f'MA_{period}'] = talib.SMA(data['close'], timeperiod=period)\n",
        "    return features\n",
        "\n",
        "def calculate_rsi(data, period=14):\n",
        "    \"\"\"Calculate RSI using CLOSE prices (1 feature)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    features['RSI_14'] = talib.RSI(data['close'], timeperiod=period)\n",
        "    return features\n",
        "\n",
        "def calculate_macd(data, fast=12, slow=26, signal=9):\n",
        "    \"\"\"Calculate MACD line, signal, and histogram (3 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    macd_line, macd_signal, macd_hist = talib.MACD(data['close'], \n",
        "                                                   fastperiod=fast, \n",
        "                                                   slowperiod=slow, \n",
        "                                                   signalperiod=signal)\n",
        "    features['MACD_line'] = macd_line\n",
        "    features['MACD_signal'] = macd_signal\n",
        "    features['MACD_hist'] = macd_hist\n",
        "    return features\n",
        "\n",
        "def calculate_ichimoku(data):\n",
        "    \"\"\"Calculate Ichimoku Cloud components (5 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    \n",
        "    # Tenkan-sen (Conversion Line)\n",
        "    high_9 = data['high'].rolling(window=9).max()\n",
        "    low_9 = data['low'].rolling(window=9).min()\n",
        "    features['conversion_line'] = (high_9 + low_9) / 2\n",
        "    \n",
        "    # Kijun-sen (Baseline)\n",
        "    high_26 = data['high'].rolling(window=26).max()\n",
        "    low_26 = data['low'].rolling(window=26).min()\n",
        "    features['baseline'] = (high_26 + low_26) / 2\n",
        "    \n",
        "    # Senkou Span A (Leading Span A)\n",
        "    features['leading_span_A'] = (features['conversion_line'] + features['baseline']) / 2\n",
        "    \n",
        "    # Senkou Span B (Leading Span B)\n",
        "    high_52 = data['high'].rolling(window=52).max()\n",
        "    low_52 = data['low'].rolling(window=52).min()\n",
        "    features['leading_span_B'] = (high_52 + low_52) / 2\n",
        "    \n",
        "    # Chikou Span (Lagging Span) - Current close compared to 26 periods ago\n",
        "    features['lagging_span'] = data['close'].shift(26)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def calculate_all_indicators(data, timeframe_name):\n",
        "    \"\"\"Calculate all 19 indicators for a timeframe\"\"\"\n",
        "    print(f\"Calculating indicators for {timeframe_name}...\")\n",
        "    \n",
        "    # Combine all indicator functions\n",
        "    ohlcv = extract_ohlcv_features(data)\n",
        "    ma = calculate_moving_averages(data)\n",
        "    rsi = calculate_rsi(data)\n",
        "    macd = calculate_macd(data)\n",
        "    ichimoku = calculate_ichimoku(data)\n",
        "    \n",
        "    # Combine all features\n",
        "    all_features = pd.concat([ohlcv, ma, rsi, macd, ichimoku], axis=1)\n",
        "    \n",
        "    # Add timeframe prefix to column names\n",
        "    all_features.columns = [f\"{timeframe_name}_{col}\" for col in all_features.columns]\n",
        "    \n",
        "    print(f\"âœ… {timeframe_name}: {len(all_features.columns)} features created\")\n",
        "    return all_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Calculating indicators on full data (including buffer)...\n",
            "Calculating indicators for H4...\n",
            "âœ… H4: 19 features created\n",
            "Calculating indicators for D1...\n",
            "âœ… D1: 19 features created\n",
            "Calculating indicators for W1...\n",
            "âœ… W1: 19 features created\n",
            "Calculating indicators for M1...\n",
            "âœ… M1: 19 features created\n",
            "âœ… All indicators calculated on full data\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Calculate Indicators on Full Data (Including Buffer)\n",
        "def calculate_indicators_on_full_data(h4_full, d1_full, w1_full, m1_full):\n",
        "    \"\"\"Calculate indicators using full data to ensure proper calculations\"\"\"\n",
        "    \n",
        "    print(\"ðŸ”„ Calculating indicators on full data (including buffer)...\")\n",
        "    \n",
        "    # Calculate indicators on full data\n",
        "    h4_indicators_full = calculate_all_indicators(h4_full, 'H4')\n",
        "    d1_indicators_full = calculate_all_indicators(d1_full, 'D1')\n",
        "    w1_indicators_full = calculate_all_indicators(w1_full, 'W1')\n",
        "    m1_indicators_full = calculate_all_indicators(m1_full, 'M1')\n",
        "    \n",
        "    print(\"âœ… All indicators calculated on full data\")\n",
        "    return h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full\n",
        "\n",
        "# Calculate indicators on full data\n",
        "h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full = calculate_indicators_on_full_data(\n",
        "    h4_full, d1_full, w1_full, m1_full\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_previous_month_timestamp(timestamp):\n",
        "    \"\"\"\n",
        "    Get the 10th day of the previous month\n",
        "    Simple and handles all edge cases!\n",
        "    \"\"\"\n",
        "    dt = pd.to_datetime(timestamp)\n",
        "    \n",
        "    # Get previous month\n",
        "    if dt.month == 1:\n",
        "        prev_month = dt.replace(year=dt.year-1, month=12, day=10)\n",
        "    else:\n",
        "        prev_month = dt.replace(month=dt.month-1, day=10)\n",
        "    \n",
        "    return prev_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ§¹ Removing problematic indicators...\n",
            "âœ… Removed W1_MA_120 (needs 2.3 years of data)\n",
            "âœ… Removed M1_MA_120 (needs 5-10 years of data)\n",
            "âœ… Removed M1_MA_60 (needs 5-10 years of data)\n",
            "âœ… Removed M1_leading_span_A (needs 5-10 years of data)\n",
            "âœ… Removed M1_leading_span_B (needs 5-10 years of data)\n",
            "âœ… Removed M1_MACD_line (needs 5-10 years of data)\n",
            "âœ… Removed M1_MACD_signal (needs 5-10 years of data)\n",
            "âœ… Removed M1_MACD_hist (needs 5-10 years of data)\n",
            "ðŸ“Š Cleaned indicators:\n",
            "  H4: 19 features (no changes)\n",
            "  D1: 19 features (no changes)\n",
            "  W1: 18 features (removed 1)\n",
            "  M1: 12 features (removed 7)\n"
          ]
        }
      ],
      "source": [
        "# Step 3.5: Remove Problematic Indicators After Calculation\n",
        "def remove_problematic_indicators(h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full):\n",
        "    \"\"\"\n",
        "    Remove indicators that cannot be calculated with available data\n",
        "    - W1: Remove 120 MA (needs 2.3 years of data)\n",
        "    - M1: Remove 120 MA, 60 MA, leading_span_A, leading_span_B (need 5-10 years of data)\n",
        "    \"\"\"\n",
        "    print(\"ðŸ§¹ Removing problematic indicators...\")\n",
        "    \n",
        "    # W1: Remove 120 MA\n",
        "    w1_indicators_clean = w1_indicators_full.copy()\n",
        "    if 'W1_MA_120' in w1_indicators_clean.columns:\n",
        "        w1_indicators_clean = w1_indicators_clean.drop('W1_MA_120', axis=1)\n",
        "        print(\"âœ… Removed W1_MA_120 (needs 2.3 years of data)\")\n",
        "    \n",
        "    # M1: Remove 120 MA, 60 MA, leading_span_A, leading_span_B\n",
        "    m1_indicators_clean = m1_indicators_full.copy()\n",
        "    problematic_m1_cols = ['M1_MA_120', 'M1_MA_60', 'M1_leading_span_A', 'M1_leading_span_B', 'M1_MACD_line', 'M1_MACD_signal', 'M1_MACD_hist']\n",
        "    \n",
        "    for col in problematic_m1_cols:\n",
        "        if col in m1_indicators_clean.columns:\n",
        "            m1_indicators_clean = m1_indicators_clean.drop(col, axis=1)\n",
        "            print(f\"âœ… Removed {col} (needs 5-10 years of data)\")\n",
        "    \n",
        "    print(f\"ðŸ“Š Cleaned indicators:\")\n",
        "    print(f\"  H4: {len(h4_indicators_full.columns)} features (no changes)\")\n",
        "    print(f\"  D1: {len(d1_indicators_full.columns)} features (no changes)\")\n",
        "    print(f\"  W1: {len(w1_indicators_clean.columns)} features (removed 1)\")\n",
        "    print(f\"  M1: {len(m1_indicators_clean.columns)} features (removed 7)\")\n",
        "    \n",
        "    return h4_indicators_full, d1_indicators_full, w1_indicators_clean, m1_indicators_clean\n",
        "\n",
        "# Remove problematic indicators\n",
        "h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean = remove_problematic_indicators(\n",
        "    h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2020-06-01 00:00:00 2025-09-01 00:00:00\n",
            "2017-12-01 00:00:00 2025-10-01 00:00:00\n",
            "2017-12-01 00:00:00 2025-10-01 00:00:00\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "m1_focused = m1_indicators_clean[(m1_indicators_clean.index >= train_start)\n",
        "                                 & (m1_indicators_clean.index <= test_end)]\n",
        "\n",
        "print(m1_focused.isnull().sum().sum())\n",
        "print(m1_focused.index.min(), m1_focused.index.max())\n",
        "print(m1_indicators_clean.index.min(), m1_indicators_clean.index.max())\n",
        "print(m1_full.index.min(), m1_full.index.max())\n",
        "print(m1_full.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Temporal Alignment Functions (CORRECTED VERSION)\n",
        "def align_timeframe_data(base_data, target_data, base_timeframe, target_timeframe):\n",
        "    \"\"\"\n",
        "    Align target timeframe data with base timeframe data using proper temporal alignment\n",
        "    \n",
        "    Args:\n",
        "        base_data: H4 data (base timeframe)\n",
        "        target_data: D1/W1/M1 data (target timeframe)\n",
        "        base_timeframe: 'H4'\n",
        "        target_timeframe: 'D1', 'W1', 'M1', 'D1_lags', 'W1_lags', 'M1_lags'\n",
        "    \n",
        "    Returns:\n",
        "        aligned_data: Target data aligned with base data timestamps\n",
        "    \"\"\"\n",
        "    print(f\"ðŸ”„ Aligning {target_timeframe} data with {base_timeframe} timestamps...\")\n",
        "    \n",
        "    # Define timeframe offsets - ADD LAG SUPPORT\n",
        "    timeframe_offsets = {\n",
        "        'D1': pd.Timedelta(days=1),\n",
        "        'W1': pd.Timedelta(weeks=1),\n",
        "        'M1':'previous_month_10th',  # Approximate month\n",
        "        # Add lag support\n",
        "        'D1_lags': pd.Timedelta(days=1),\n",
        "        'W1_lags': pd.Timedelta(weeks=1),\n",
        "        'M1_lags': 'previous_month_10th'\n",
        "    }\n",
        "    \n",
        "    aligned_data = pd.DataFrame(index=base_data.index, columns=target_data.columns)\n",
        "    \n",
        "    for base_timestamp in base_data.index:\n",
        "        # Calculate the cutoff time\n",
        "        if timeframe_offsets[target_timeframe] == 'previous_month_10th':\n",
        "            # Use our new function for month alignment\n",
        "            cutoff_time = get_previous_month_timestamp(base_timestamp)\n",
        "        else:\n",
        "            # Use regular timedelta for other timeframes\n",
        "            offset = timeframe_offsets[target_timeframe]\n",
        "            cutoff_time = base_timestamp - offset\n",
        "        \n",
        "        # Find target data that is <= cutoff_time (previous completed data)\n",
        "        available_target_data = target_data[target_data.index <= cutoff_time]\n",
        "        \n",
        "        if len(available_target_data) > 0:\n",
        "            # Use the most recent available data (previous completed)\n",
        "            latest_target_data = available_target_data.iloc[-1]\n",
        "            aligned_data.loc[base_timestamp] = latest_target_data\n",
        "        else:\n",
        "            # If no data available, fill with NaN\n",
        "            aligned_data.loc[base_timestamp] = np.nan\n",
        "    \n",
        "    print(f\"âœ… {target_timeframe} data aligned: {len(aligned_data.columns)} features, {len(aligned_data)} records\")\n",
        "    return aligned_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Aligning D1 data with H4 timestamps...\n",
            "âœ… D1 data aligned: 19 features, 12368 records\n",
            "ðŸ”„ Aligning W1 data with H4 timestamps...\n",
            "âœ… W1 data aligned: 18 features, 12368 records\n",
            "ðŸ”„ Aligning M1 data with H4 timestamps...\n",
            "âœ… M1 data aligned: 12 features, 12368 records\n",
            "âœ… Feature sets A0â†’A3 created with cleaned indicators:\n",
            "  A0: 19 features, 12368 records\n",
            "  A1: 38 features, 12368 records\n",
            "  A2: 56 features, 12368 records\n",
            "  A3: 68 features, 12368 records\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Create Feature Sets A0â†’A3 with Cleaned Indicators\n",
        "def create_feature_sets_with_cleaned_indicators(h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean):\n",
        "    \"\"\"Create feature sets A0â†’A3 using cleaned indicators (no problematic indicators)\"\"\"\n",
        "    \n",
        "    # A0: H4 indicators only\n",
        "    A0 = h4_indicators_clean.copy()\n",
        "    \n",
        "    # A1: H4 + D1 indicators - Align D1 with H4 timestamps\n",
        "    d1_aligned = align_timeframe_data(A0, d1_indicators_clean, 'H4', 'D1')\n",
        "    A1 = pd.concat([h4_indicators_clean, d1_aligned], axis=1)\n",
        "    \n",
        "    # A2: H4 + D1 + W1 indicators - Align W1 with H4 timestamps\n",
        "    w1_aligned = align_timeframe_data(A0, w1_indicators_clean, 'H4', 'W1')\n",
        "    A2 = pd.concat([h4_indicators_clean, d1_aligned, w1_aligned], axis=1)\n",
        "    \n",
        "    # A3: H4 + D1 + W1 + M1 indicators - Align M1 with H4 timestamps\n",
        "    m1_aligned = align_timeframe_data(A0, m1_indicators_clean, 'H4', 'M1')\n",
        "    A3 = pd.concat([h4_indicators_clean, d1_aligned, w1_aligned, m1_aligned], axis=1)\n",
        "    \n",
        "    print(f\"âœ… Feature sets A0â†’A3 created with cleaned indicators:\")\n",
        "    print(f\"  A0: {len(A0.columns)} features, {len(A0)} records\")\n",
        "    print(f\"  A1: {len(A1.columns)} features, {len(A1)} records\")\n",
        "    print(f\"  A2: {len(A2.columns)} features, {len(A2)} records\")\n",
        "    print(f\"  A3: {len(A3.columns)} features, {len(A3)} records\")\n",
        "    \n",
        "    return A0, A1, A2, A3\n",
        "\n",
        "# Create feature sets with cleaned indicators\n",
        "A0, A1, A2, A3 = create_feature_sets_with_cleaned_indicators(\n",
        "    h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Feature Set Validation:\n",
            "A0_focused.isnull().sum().sum(): 0\n",
            "A1_focused.isnull().sum().sum(): 0\n",
            "A2_focused.isnull().sum().sum(): 0\n",
            "A3_focused.isnull().sum().sum(): 0\n"
          ]
        }
      ],
      "source": [
        "def validate_A0_to_A3(A0, A1, A2, A3):\n",
        "    \"\"\"Validate feature sets A0â†’A3\"\"\"\n",
        "    print(\"ðŸ” Feature Set Validation:\")\n",
        "    train_start = '2020-05-12'\n",
        "    test_end = '2025-09-19'\n",
        "\n",
        "    A0_focused = A0[(A0.index >= train_start) & (A0.index <= test_end)]\n",
        "    A1_focused = A1[(A1.index >= train_start) & (A1.index <= test_end)]\n",
        "    A2_focused = A2[(A2.index >= train_start) & (A2.index <= test_end)]\n",
        "    A3_focused = A3[(A3.index >= train_start) & (A3.index <= test_end)]\n",
        "\n",
        "    print(\n",
        "        f\"A0_focused.isnull().sum().sum(): {A0_focused.isnull().sum().sum()}\")\n",
        "    print(\n",
        "        f\"A1_focused.isnull().sum().sum(): {A1_focused.isnull().sum().sum()}\")\n",
        "    print(\n",
        "        f\"A2_focused.isnull().sum().sum(): {A2_focused.isnull().sum().sum()}\")\n",
        "    print(\n",
        "        f\"A3_focused.isnull().sum().sum(): {A3_focused.isnull().sum().sum()}\")\n",
        "\n",
        "validate_A0_to_A3(A0, A1, A2, A3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â° Creating historical lag features using full data (including buffer)...\n",
            "âœ… H4 lags: 114 features created\n",
            "âœ… D1 lags: 133 features created\n",
            "âœ… W1 lags: 72 features created\n",
            "âœ… M1 lags: 24 features created\n",
            "âœ… All lag features created using full data:\n",
            "  H4 lags: 114 features, 12368 records\n",
            "  D1 lags: 133 features, 2146 records\n",
            "  W1 lags: 72 features, 350 records\n",
            "  M1 lags: 24 features, 95 records\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Create Historical Lag Features (Using Full Data with Buffer)\n",
        "def create_lag_features(indicators_full, timeframe_name, lag_periods):\n",
        "    \"\"\"Create historical lag features for a timeframe using full data (including buffer)\"\"\"\n",
        "    lag_features = pd.DataFrame(index=indicators_full.index)\n",
        "    \n",
        "    for lag in lag_periods:\n",
        "        for col in indicators_full.columns:\n",
        "            lag_features[f\"{col}_lag_{lag}\"] = indicators_full[col].shift(lag)\n",
        "    \n",
        "    print(f\"âœ… {timeframe_name} lags: {len(lag_features.columns)} features created\")\n",
        "    return lag_features\n",
        "\n",
        "def create_all_lag_features_with_buffer(h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean):\n",
        "    \"\"\"Create historical lag features for all timeframes using full data (including buffer)\"\"\"\n",
        "    \n",
        "    print(\"â° Creating historical lag features using full data (including buffer)...\")\n",
        "    \n",
        "    # H4 lags: t-1 to t-6 (6 lags)\n",
        "    h4_lags_full = create_lag_features(h4_indicators_clean, 'H4', range(1, 7))\n",
        "    \n",
        "    # D1 lags: t-1 to t-7 (7 lags)\n",
        "    d1_lags_full = create_lag_features(d1_indicators_clean, 'D1', range(1, 8))\n",
        "    \n",
        "    # W1 lags: t-1 to t-4 (4 lags)\n",
        "    w1_lags_full = create_lag_features(w1_indicators_clean, 'W1', range(1, 5))\n",
        "    \n",
        "    # M1 lags: t-1 to t-2 (2 lags)\n",
        "    m1_lags_full = create_lag_features(m1_indicators_clean, 'M1', range(1, 3))\n",
        "    \n",
        "    print(f\"âœ… All lag features created using full data:\")\n",
        "    print(f\"  H4 lags: {len(h4_lags_full.columns)} features, {len(h4_lags_full)} records\")\n",
        "    print(f\"  D1 lags: {len(d1_lags_full.columns)} features, {len(d1_lags_full)} records\")\n",
        "    print(f\"  W1 lags: {len(w1_lags_full.columns)} features, {len(w1_lags_full)} records\")\n",
        "    print(f\"  M1 lags: {len(m1_lags_full.columns)} features, {len(m1_lags_full)} records\")\n",
        "    \n",
        "    return h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full\n",
        "\n",
        "# Create historical lag features using full data (including buffer)\n",
        "h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full = create_all_lag_features_with_buffer(\n",
        "    h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2020-05-12 00:00:00 2025-09-19 00:00:00\n",
            "0\n",
            "2020-05-12 00:00:00 2025-09-19 00:00:00\n",
            "0\n",
            "2020-05-18 00:00:00 2025-09-15 00:00:00\n",
            "0\n",
            "2020-06-01 00:00:00 2025-09-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "h4_lags_focused=h4_lags_full[(h4_lags_full.index >= train_start) & (h4_lags_full.index <= test_end)]\n",
        "print(h4_lags_focused.isnull().sum().sum())\n",
        "print(h4_lags_focused.index.min(), h4_lags_focused.index.max())\n",
        "\n",
        "d1_lags_focused = d1_lags_full[(d1_lags_full.index >= train_start)\n",
        "                               & (d1_lags_full.index <= test_end)]\n",
        "print(d1_lags_focused.isnull().sum().sum())\n",
        "print(d1_lags_focused.index.min(), d1_lags_focused.index.max())\n",
        "\n",
        "w1_lags_focused = w1_lags_full[(w1_lags_full.index >= train_start)\n",
        "                              & (w1_lags_full.index <= test_end)]\n",
        "print(w1_lags_focused.isnull().sum().sum())\n",
        "print(w1_lags_focused.index.min(), w1_lags_focused.index.max())\n",
        "\n",
        "m1_lags_focused = m1_lags_full[(m1_lags_full.index >= train_start)\n",
        "                              & (m1_lags_full.index <= test_end)]\n",
        "print(m1_lags_focused.isnull().sum().sum())\n",
        "print(m1_lags_focused.index.min(), m1_lags_focused.index.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            D1_open_lag_1  D1_high_lag_1  D1_low_lag_1  D1_close_lag_1  \\\n",
            "timestamp                                                                \n",
            "2020-05-12          False          False         False           False   \n",
            "2020-05-13          False          False         False           False   \n",
            "2020-05-14          False          False         False           False   \n",
            "2020-05-15          False          False         False           False   \n",
            "2020-05-16          False          False         False           False   \n",
            "\n",
            "            D1_volume_lag_1  D1_MA_7_lag_1  D1_MA_14_lag_1  D1_MA_20_lag_1  \\\n",
            "timestamp                                                                    \n",
            "2020-05-12            False          False           False           False   \n",
            "2020-05-13            False          False           False           False   \n",
            "2020-05-14            False          False           False           False   \n",
            "2020-05-15            False          False           False           False   \n",
            "2020-05-16            False          False           False           False   \n",
            "\n",
            "            D1_MA_60_lag_1  D1_MA_120_lag_1  ...  D1_MA_120_lag_7  \\\n",
            "timestamp                                    ...                    \n",
            "2020-05-12           False            False  ...            False   \n",
            "2020-05-13           False            False  ...            False   \n",
            "2020-05-14           False            False  ...            False   \n",
            "2020-05-15           False            False  ...            False   \n",
            "2020-05-16           False            False  ...            False   \n",
            "\n",
            "            D1_RSI_14_lag_7  D1_MACD_line_lag_7  D1_MACD_signal_lag_7  \\\n",
            "timestamp                                                               \n",
            "2020-05-12            False               False                 False   \n",
            "2020-05-13            False               False                 False   \n",
            "2020-05-14            False               False                 False   \n",
            "2020-05-15            False               False                 False   \n",
            "2020-05-16            False               False                 False   \n",
            "\n",
            "            D1_MACD_hist_lag_7  D1_conversion_line_lag_7  D1_baseline_lag_7  \\\n",
            "timestamp                                                                     \n",
            "2020-05-12               False                     False              False   \n",
            "2020-05-13               False                     False              False   \n",
            "2020-05-14               False                     False              False   \n",
            "2020-05-15               False                     False              False   \n",
            "2020-05-16               False                     False              False   \n",
            "\n",
            "            D1_leading_span_A_lag_7  D1_leading_span_B_lag_7  \\\n",
            "timestamp                                                      \n",
            "2020-05-12                    False                    False   \n",
            "2020-05-13                    False                    False   \n",
            "2020-05-14                    False                    False   \n",
            "2020-05-15                    False                    False   \n",
            "2020-05-16                    False                    False   \n",
            "\n",
            "            D1_lagging_span_lag_7  \n",
            "timestamp                          \n",
            "2020-05-12                  False  \n",
            "2020-05-13                  False  \n",
            "2020-05-14                  False  \n",
            "2020-05-15                  False  \n",
            "2020-05-16                  False  \n",
            "\n",
            "[5 rows x 133 columns]\n"
          ]
        }
      ],
      "source": [
        "print(d1_lags_focused.isnull().head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Aligning D1_lags data with H4 timestamps...\n",
            "âœ… D1_lags data aligned: 133 features, 12368 records\n",
            "ðŸ”„ Aligning W1_lags data with H4 timestamps...\n",
            "âœ… W1_lags data aligned: 72 features, 12368 records\n",
            "ðŸ”„ Aligning M1_lags data with H4 timestamps...\n",
            "âœ… M1_lags data aligned: 24 features, 12368 records\n",
            "âœ… A4 feature set created with temporal alignment:\n",
            "  A4: 411 features, 12368 records\n",
            "  - Current indicators: 68\n",
            "  - Historical lags: 343\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Create A4 Feature Set with Temporal Alignment (Using Full Data)\n",
        "def create_a4_features_with_temporal_alignment(A3, h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full):\n",
        "    \"\"\"Create A4 feature set: A3 + all historical lags with proper temporal alignment\"\"\"\n",
        "    \n",
        "    # Align D1, W1, M1 lag features with H4 timestamps\n",
        "    d1_lags_aligned = align_timeframe_data(A3, d1_lags_full, 'H4', 'D1_lags')\n",
        "    w1_lags_aligned = align_timeframe_data(A3, w1_lags_full, 'H4', 'W1_lags')\n",
        "    m1_lags_aligned = align_timeframe_data(A3, m1_lags_full, 'H4', 'M1_lags')\n",
        "    \n",
        "    # Combine A3 with all lag features\n",
        "    A4 = pd.concat([A3, h4_lags_full, d1_lags_aligned, w1_lags_aligned, m1_lags_aligned], axis=1)\n",
        "    \n",
        "    print(f\"âœ… A4 feature set created with temporal alignment:\")\n",
        "    print(f\"  A4: {len(A4.columns)} features, {len(A4)} records\")\n",
        "    print(f\"  - Current indicators: {len(A3.columns)}\")\n",
        "    print(f\"  - Historical lags: {len(A4.columns) - len(A3.columns)}\")\n",
        "    \n",
        "    return A4\n",
        "\n",
        "# Create A4 feature set with temporal alignment\n",
        "A4 = create_a4_features_with_temporal_alignment(A3, h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Feature Set Validation (Train/Test Period Only):\n",
            "ðŸ“… Period: 2020-05-12 to 2025-09-19\n",
            "ðŸ” Feature Set Validation:\n",
            "  âœ… A0: 19/19 features\n",
            "  âœ… A1: 38/38 features\n",
            "  âœ… A2: 56/56 features\n",
            "  âŒ A3: 68/67 features\n",
            "  âŒ A4: 411/416 features\n",
            "\n",
            "ðŸ” Missing Values Check (Train/Test Period Only):\n",
            "  A0: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A1: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A2: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A3: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A4: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Data Validation & Quality Checks\n",
        "def validate_feature_sets(A0,\n",
        "                          A1,\n",
        "                          A2,\n",
        "                          A3,\n",
        "                          A4,\n",
        "                          train_start='2020-05-12',\n",
        "                          test_end='2025-09-19'):\n",
        "    \"\"\"Validate all feature sets\"\"\"\n",
        "    print(\"ðŸ” Feature Set Validation (Train/Test Period Only):\")\n",
        "    print(f\"ðŸ“… Period: {train_start} to {test_end}\")\n",
        "\n",
        "    A0_focused = A0[(A0.index >= train_start) & (A0.index <= test_end)]\n",
        "    A1_focused = A1[(A1.index >= train_start) & (A1.index <= test_end)]\n",
        "    A2_focused = A2[(A2.index >= train_start) & (A2.index <= test_end)]\n",
        "    A3_focused = A3[(A3.index >= train_start) & (A3.index <= test_end)]\n",
        "    A4_focused = A4[(A4.index >= train_start) & (A4.index <= test_end)]\n",
        "\n",
        "    feature_counts = {\n",
        "        'A0': len(A0_focused.columns),\n",
        "        'A1': len(A1_focused.columns),\n",
        "        'A2': len(A2_focused.columns),\n",
        "        'A3': len(A3_focused.columns),\n",
        "        'A4': len(A4_focused.columns)\n",
        "    }\n",
        "\n",
        "    # A0 : 19, A1 : 38, A2 : 38 + 19 - 1= 56,  A3 : 56 + 19 - 4 = 71, A4 : \n",
        "    expected_counts = {'A0': 19, 'A1': 38, 'A2': 56, 'A3': 68, 'A4': 411}\n",
        "\n",
        "    print(\"ðŸ” Feature Set Validation:\")\n",
        "    for set_name, count in feature_counts.items():\n",
        "        expected = expected_counts[set_name]\n",
        "        status = \"âœ…\" if count == expected else \"âŒ\"\n",
        "        print(f\"  {status} {set_name}: {count}/{expected} features\")\n",
        "\n",
        "    # Check for missing values in focused period only\n",
        "    print(\"\\nðŸ” Missing Values Check (Train/Test Period Only):\")\n",
        "    for set_name, features in [('A0', A0_focused), ('A1', A1_focused),\n",
        "                               ('A2', A2_focused), ('A3', A3_focused),\n",
        "                               ('A4', A4_focused)]:\n",
        "        missing_count = features.isnull().sum().sum()\n",
        "        total_cells = features.shape[0] * features.shape[1]\n",
        "        missing_percentage = (missing_count / total_cells) * 100\n",
        "        print(\n",
        "            f\"  {set_name}: {missing_count:,} missing values ({missing_percentage:.2f}%)\"\n",
        "        )\n",
        "        print(f\"    Period: {features.index[0]} to {features.index[-1]}\")\n",
        "        print(f\"    Records: {len(features)}\")\n",
        "\n",
        "    return feature_counts, (A0_focused, A1_focused, A2_focused, A3_focused,\n",
        "                            A4_focused)\n",
        "\n",
        "# Validate feature sets\n",
        "validation_results_focused, focused_sets = validate_feature_sets(A0, A1, A2, A3, A4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M1 data availability:\n",
            "First M1 timestamp: 2017-12-01 00:00:00\n",
            "Last M1 timestamp: 2025-10-01 00:00:00\n",
            "Total M1 records: 95\n",
            "M1 temporal alignment check:\n",
            "A3 missing values: 0\n",
            "A3 M1 columns missing: 0\n",
            "Lag feature missing values:\n",
            "A4 H4 lags missing: 0\n",
            "A4 D1 lags missing: 0\n",
            "A4 W1 lags missing: 0\n",
            "A4 M1 lags missing: 0\n"
          ]
        }
      ],
      "source": [
        "*_,A3_focused,A4_focused=focused_sets\n",
        "# Check when M1 data becomes available\n",
        "print(\"M1 data availability:\")\n",
        "print(f\"First M1 timestamp: {m1_indicators_clean.index[0]}\")\n",
        "print(f\"Last M1 timestamp: {m1_indicators_clean.index[-1]}\")\n",
        "print(f\"Total M1 records: {len(m1_indicators_clean)}\")\n",
        "\n",
        "\n",
        "# Check if M1 alignment is working correctly\n",
        "print(\"M1 temporal alignment check:\")\n",
        "print(f\"A3 missing values: {A3_focused.isnull().sum().sum()}\")\n",
        "print(\n",
        "    f\"A3 M1 columns missing: {A3_focused.filter(regex='M1_').isnull().sum().sum()}\"\n",
        ")\n",
        "\n",
        "# Check lag feature missing values\n",
        "print(\"Lag feature missing values:\")\n",
        "print(f\"A4 H4 lags missing: {A4_focused.filter(regex='H4_.*_lag_').isnull().sum().sum()}\")\n",
        "print(f\"A4 D1 lags missing: {A4_focused.filter(regex='D1_.*_lag_').isnull().sum().sum()}\")\n",
        "print(f\"A4 W1 lags missing: {A4_focused.filter(regex='W1_.*_lag_').isnull().sum().sum()}\")\n",
        "print(f\"A4 M1 lags missing: {A4_focused.filter(regex='M1_.*_lag_').isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ¯ Creating target variable (vectorized first threshold logic)...\n",
            "ðŸ”„ Calculating target labels...\n",
            "   Processing 0/12368 records...\n",
            "   Processing 1000/12368 records...\n",
            "   Processing 2000/12368 records...\n",
            "   Processing 3000/12368 records...\n",
            "   Processing 4000/12368 records...\n",
            "   Processing 5000/12368 records...\n",
            "   Processing 6000/12368 records...\n",
            "   Processing 7000/12368 records...\n",
            "   Processing 8000/12368 records...\n",
            "   Processing 9000/12368 records...\n",
            "   Processing 10000/12368 records...\n",
            "   Processing 11000/12368 records...\n",
            "   Processing 12000/12368 records...\n",
            "âœ… Target variable created:\n",
            "   Total records: 11737\n",
            "   Sell labels: 2733\n",
            "   Rest labels: 9004\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-05-12 00:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 04:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 08:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 12:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 16:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 08:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 12:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 16:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 20:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-19 00:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11737 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     target\n",
              "timestamp                  \n",
              "2020-05-12 00:00:00       0\n",
              "2020-05-12 04:00:00       0\n",
              "2020-05-12 08:00:00       0\n",
              "2020-05-12 12:00:00       0\n",
              "2020-05-12 16:00:00       0\n",
              "...                     ...\n",
              "2025-09-18 08:00:00       0\n",
              "2025-09-18 12:00:00       0\n",
              "2025-09-18 16:00:00       0\n",
              "2025-09-18 20:00:00       0\n",
              "2025-09-19 00:00:00       0\n",
              "\n",
              "[11737 rows x 1 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_target_variable_first_threshold_vectorized(h4_full,\n",
        "                                                      train_start='2020-05-12',\n",
        "                                                      test_end='2025-09-19'):\n",
        "    \"\"\"\n",
        "    Create target variable using vectorized operations for efficiency\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"ðŸŽ¯ Creating target variable (vectorized first threshold logic)...\")\n",
        "\n",
        "    # Create target variable for ALL H4 data\n",
        "    y_full = pd.DataFrame(index=h4_full.index)\n",
        "    y_full['target'] = 0  # Initialize with 0\n",
        "\n",
        "    print(\"ðŸ”„ Calculating target labels...\")\n",
        "\n",
        "    for i in range(len(h4_full)):\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"   Processing {i}/{len(h4_full)} records...\")\n",
        "\n",
        "        current_close = h4_full.iloc[i]['close']\n",
        "\n",
        "        # Get next 180 periods (30 days * 6 periods per day)\n",
        "        if i + 180 < len(h4_full):\n",
        "            future_data = h4_full.iloc[i + 1:i + 181]\n",
        "\n",
        "            # Calculate price changes\n",
        "            price_increases = (future_data['close'] - current_close) / current_close\n",
        "            price_drops = (future_data['low'] - current_close) / current_close\n",
        "\n",
        "            # Find first threshold and assign directly\n",
        "            for j in range(len(future_data)):\n",
        "                # Check +5% threshold first\n",
        "                if price_increases.iloc[j] >= 0.10:\n",
        "                    y_full.iloc[i, 0] = 0  # BUY first - assign and break\n",
        "                    break\n",
        "                \n",
        "                # Check -15% threshold\n",
        "                if price_drops.iloc[j] <= -0.15:\n",
        "                    y_full.iloc[i, 0] = 1  # SELL first - assign and break\n",
        "                    break\n",
        "            else:\n",
        "                # If loop completes without break, neither threshold reached\n",
        "                y_full.iloc[i, 0] = 0  # Default to REST\n",
        "\n",
        "                # Filter to focused period\n",
        "                y_focused = y_full[(y_full.index >= train_start)\n",
        "                                & (y_full.index <= test_end)]\n",
        "\n",
        "    print(f\"âœ… Target variable created:\")\n",
        "    print(f\"   Total records: {len(y_focused)}\")\n",
        "    print(f\"   Sell labels: {y_focused['target'].sum()}\")\n",
        "    print(f\"   Rest labels: {len(y_focused) - y_focused['target'].sum()}\")\n",
        "\n",
        "    return y_focused\n",
        "\n",
        "create_target_variable_first_threshold_vectorized(h4_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ’¾ Saving focused feature sets...\n",
            "ðŸŽ¯ Creating target variable (vectorized first threshold logic)...\n",
            "ðŸ”„ Calculating target labels...\n",
            "   Processing 0/12368 records...\n",
            "   Processing 1000/12368 records...\n",
            "   Processing 2000/12368 records...\n",
            "   Processing 3000/12368 records...\n",
            "   Processing 4000/12368 records...\n",
            "   Processing 5000/12368 records...\n",
            "   Processing 6000/12368 records...\n",
            "   Processing 7000/12368 records...\n",
            "   Processing 8000/12368 records...\n",
            "   Processing 9000/12368 records...\n",
            "   Processing 10000/12368 records...\n",
            "   Processing 11000/12368 records...\n",
            "   Processing 12000/12368 records...\n",
            "âœ… Target variable created:\n",
            "   Total records: 11737\n",
            "   Sell labels: 9046\n",
            "   Rest labels: 2691\n",
            "ðŸŽ‰ All feature sets saved successfully!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(                       H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  H4_RSI_14  H4_MACD_line  H4_MACD_signal  \\\n",
              " timestamp                                                                     \n",
              " 2020-05-12 00:00:00    8496.361583  41.982660   -185.647639     -149.012220   \n",
              " 2020-05-12 04:00:00    8510.644417  40.692031   -185.576736     -156.325123   \n",
              " 2020-05-12 08:00:00    8526.020417  45.080613   -171.849769     -159.430052   \n",
              " 2020-05-12 12:00:00    8540.649750  47.027084   -153.807846     -158.305611   \n",
              " 2020-05-12 16:00:00    8554.871583  45.081508   -143.944825     -155.433454   \n",
              " ...                            ...        ...           ...             ...   \n",
              " 2025-09-18 08:00:00  112520.355583  58.601589    483.262045      424.949027   \n",
              " 2025-09-18 12:00:00  112597.000000  61.876712    530.800011      446.119224   \n",
              " 2025-09-18 16:00:00  112673.985000  60.554112    551.358246      467.167028   \n",
              " 2025-09-18 20:00:00  112746.452750  56.857108    531.133293      479.960281   \n",
              " 2025-09-19 00:00:00  112817.630917  55.920549    501.580601      484.284345   \n",
              " \n",
              "                      H4_MACD_hist  H4_conversion_line  H4_baseline  \\\n",
              " timestamp                                                            \n",
              " 2020-05-12 00:00:00    -36.635420            8684.000      9092.00   \n",
              " 2020-05-12 04:00:00    -29.251613            8684.000      9076.48   \n",
              " 2020-05-12 08:00:00    -12.419717            8684.000      9061.99   \n",
              " 2020-05-12 12:00:00      4.497765            8684.000      9061.99   \n",
              " 2020-05-12 16:00:00     11.488629            8684.000      9061.99   \n",
              " ...                           ...                 ...          ...   \n",
              " 2025-09-18 08:00:00     58.313018          116308.405    116140.00   \n",
              " 2025-09-18 12:00:00     84.680787          116308.405    116140.00   \n",
              " 2025-09-18 16:00:00     84.191218          116310.405    116142.00   \n",
              " 2025-09-18 20:00:00     51.173012          116310.405    116142.00   \n",
              " 2025-09-19 00:00:00     17.296256          116310.405    116142.00   \n",
              " \n",
              "                      H4_leading_span_A  H4_leading_span_B  H4_lagging_span  \n",
              " timestamp                                                                   \n",
              " 2020-05-12 00:00:00          8888.0000           9092.000          9863.93  \n",
              " 2020-05-12 04:00:00          8880.2400           9092.000          9986.40  \n",
              " 2020-05-12 08:00:00          8872.9950           9092.000          9930.69  \n",
              " 2020-05-12 12:00:00          8872.9950           9092.000          9810.14  \n",
              " 2020-05-12 16:00:00          8872.9950           9092.000          9899.75  \n",
              " ...                                ...                ...              ...  \n",
              " 2025-09-18 08:00:00        116224.2025         114406.725        115679.98  \n",
              " 2025-09-18 12:00:00        116224.2025         114406.725        115805.39  \n",
              " 2025-09-18 16:00:00        116226.2025         114636.210        115794.91  \n",
              " 2025-09-18 20:00:00        116226.2025         114998.600        115224.01  \n",
              " 2025-09-19 00:00:00        116226.2025         115099.995        115634.99  \n",
              " \n",
              " [11737 rows x 19 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...      D1_MA_120  D1_RSI_14  \\\n",
              " timestamp                           ...                             \n",
              " 2020-05-12 00:00:00    8496.361583  ...    8134.400833  52.874315   \n",
              " 2020-05-12 04:00:00    8510.644417  ...    8134.400833  52.874315   \n",
              " 2020-05-12 08:00:00    8526.020417  ...    8134.400833  52.874315   \n",
              " 2020-05-12 12:00:00    8540.649750  ...    8134.400833  52.874315   \n",
              " 2020-05-12 16:00:00    8554.871583  ...    8134.400833  52.874315   \n",
              " ...                            ...  ...            ...        ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...  111815.687833    59.4072   \n",
              " 2025-09-18 12:00:00  112597.000000  ...  111815.687833    59.4072   \n",
              " 2025-09-18 16:00:00  112673.985000  ...  111815.687833    59.4072   \n",
              " 2025-09-18 20:00:00  112746.452750  ...  111815.687833    59.4072   \n",
              " 2025-09-19 00:00:00  112817.630917  ...  111877.600667  61.177934   \n",
              " \n",
              "                      D1_MACD_line  D1_MACD_signal  D1_MACD_hist  \\\n",
              " timestamp                                                         \n",
              " 2020-05-12 00:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 04:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 08:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 12:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 16:00:00    515.398008       544.23139    -28.833382   \n",
              " ...                           ...             ...           ...   \n",
              " 2025-09-18 08:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-18 12:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-18 16:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-18 20:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-19 00:00:00    908.385644      251.753752    656.631892   \n",
              " \n",
              "                      D1_conversion_line  D1_baseline  D1_leading_span_A  \\\n",
              " timestamp                                                                 \n",
              " 2020-05-12 00:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 04:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 08:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 12:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 16:00:00              9092.0     8267.635          8679.8175   \n",
              " ...                                 ...          ...                ...   \n",
              " 2025-09-18 08:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-18 12:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-18 16:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-18 20:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-19 00:00:00          114408.725     112577.5        113493.1125   \n",
              " \n",
              "                      D1_leading_span_B D1_lagging_span  \n",
              " timestamp                                               \n",
              " 2020-05-12 00:00:00             7877.5         6621.24  \n",
              " 2020-05-12 04:00:00             7877.5         6621.24  \n",
              " 2020-05-12 08:00:00             7877.5         6621.24  \n",
              " 2020-05-12 12:00:00             7877.5         6621.24  \n",
              " 2020-05-12 16:00:00             7877.5         6621.24  \n",
              " ...                                ...             ...  \n",
              " 2025-09-18 08:00:00           115864.5       116935.99  \n",
              " 2025-09-18 12:00:00           115864.5       116935.99  \n",
              " 2025-09-18 16:00:00           115864.5       116935.99  \n",
              " 2025-09-18 20:00:00           115864.5       116935.99  \n",
              " 2025-09-19 00:00:00           115864.5       115438.05  \n",
              " \n",
              " [11737 rows x 38 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...      W1_MA_60  W1_RSI_14  \\\n",
              " timestamp                           ...                            \n",
              " 2020-05-12 00:00:00    8496.361583  ...   8250.270333  55.285125   \n",
              " 2020-05-12 04:00:00    8510.644417  ...   8250.270333  55.285125   \n",
              " 2020-05-12 08:00:00    8526.020417  ...   8250.270333  55.285125   \n",
              " 2020-05-12 12:00:00    8540.649750  ...   8250.270333  55.285125   \n",
              " 2020-05-12 16:00:00    8554.871583  ...   8250.270333  55.285125   \n",
              " ...                            ...  ...           ...        ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...  90905.399667  59.230544   \n",
              " 2025-09-18 12:00:00  112597.000000  ...  90905.399667  59.230544   \n",
              " 2025-09-18 16:00:00  112673.985000  ...  90905.399667  59.230544   \n",
              " 2025-09-18 20:00:00  112746.452750  ...  90905.399667  59.230544   \n",
              " 2025-09-19 00:00:00  112817.630917  ...  90905.399667  59.230544   \n",
              " \n",
              "                      W1_MACD_line  W1_MACD_signal  W1_MACD_hist  \\\n",
              " timestamp                                                         \n",
              " 2020-05-12 00:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 04:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 08:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 12:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 16:00:00   -100.083928      -197.59971     97.515782   \n",
              " ...                           ...             ...           ...   \n",
              " 2025-09-18 08:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-18 12:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-18 16:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-18 20:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-19 00:00:00   5766.790835     6532.774439   -765.983604   \n",
              " \n",
              "                      W1_conversion_line  W1_baseline  W1_leading_span_A  \\\n",
              " timestamp                                                                 \n",
              " 2020-05-12 00:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 04:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 08:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 12:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 16:00:00            6924.565     7141.065           7032.815   \n",
              " ...                                 ...          ...                ...   \n",
              " 2025-09-18 08:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-18 12:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-18 16:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-18 20:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-19 00:00:00            115864.5      99491.0          107677.75   \n",
              " \n",
              "                      W1_leading_span_B W1_lagging_span  \n",
              " timestamp                                               \n",
              " 2020-05-12 00:00:00           8876.065         9039.47  \n",
              " 2020-05-12 04:00:00           8876.065         9039.47  \n",
              " 2020-05-12 08:00:00           8876.065         9039.47  \n",
              " 2020-05-12 12:00:00           8876.065         9039.47  \n",
              " 2020-05-12 16:00:00           8876.065         9039.47  \n",
              " ...                                ...             ...  \n",
              " 2025-09-18 08:00:00           90983.65        82574.53  \n",
              " 2025-09-18 12:00:00           90983.65        82574.53  \n",
              " 2025-09-18 16:00:00           90983.65        82574.53  \n",
              " 2025-09-18 20:00:00           90983.65        82574.53  \n",
              " 2025-09-19 00:00:00           90983.65        82574.53  \n",
              " \n",
              " [11737 rows x 56 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...    M1_low   M1_close       M1_volume  \\\n",
              " timestamp                           ...                                        \n",
              " 2020-05-12 00:00:00    8496.361583  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 04:00:00    8510.644417  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 08:00:00    8526.020417  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 12:00:00    8540.649750  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 16:00:00    8554.871583  ...   6150.11     8620.0  2528373.691121   \n",
              " ...                            ...  ...       ...        ...             ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-18 12:00:00  112597.000000  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-18 16:00:00  112673.985000  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-18 20:00:00  112746.452750  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-19 00:00:00  112817.630917  ...  107350.1  108246.35   471366.942936   \n",
              " \n",
              "                           M1_MA_7      M1_MA_14    M1_MA_20  M1_RSI_14  \\\n",
              " timestamp                                                                \n",
              " 2020-05-12 00:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 04:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 08:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 12:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 16:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " ...                           ...           ...         ...        ...   \n",
              " 2025-09-18 08:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-18 12:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-18 16:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-18 20:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-19 00:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " \n",
              "                      M1_conversion_line  M1_baseline M1_lagging_span  \n",
              " timestamp                                                             \n",
              " 2020-05-12 00:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 04:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 08:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 12:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 16:00:00            8056.415      8563.13        10326.76  \n",
              " ...                                 ...          ...             ...  \n",
              " 2025-09-18 08:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-18 12:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-18 16:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-18 20:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-19 00:00:00             99491.0      74687.5         30472.0  \n",
              " \n",
              " [11737 rows x 68 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...  M1_low_lag_2  M1_close_lag_2  \\\n",
              " timestamp                           ...                                 \n",
              " 2020-05-12 00:00:00    8496.361583  ...        8445.0         8523.61   \n",
              " 2020-05-12 04:00:00    8510.644417  ...        8445.0         8523.61   \n",
              " 2020-05-12 08:00:00    8526.020417  ...        8445.0         8523.61   \n",
              " 2020-05-12 12:00:00    8540.649750  ...        8445.0         8523.61   \n",
              " 2020-05-12 16:00:00    8554.871583  ...        8445.0         8523.61   \n",
              " ...                            ...  ...           ...             ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...       98200.0        107146.5   \n",
              " 2025-09-18 12:00:00  112597.000000  ...       98200.0        107146.5   \n",
              " 2025-09-18 16:00:00  112673.985000  ...       98200.0        107146.5   \n",
              " 2025-09-18 20:00:00  112746.452750  ...       98200.0        107146.5   \n",
              " 2025-09-19 00:00:00  112817.630917  ...       98200.0        107146.5   \n",
              " \n",
              "                      M1_volume_lag_2  M1_MA_7_lag_2  M1_MA_14_lag_2  \\\n",
              " timestamp                                                             \n",
              " 2020-05-12 00:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 04:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 08:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 12:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 16:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " ...                              ...            ...             ...   \n",
              " 2025-09-18 08:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-18 12:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-18 16:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-18 20:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-19 00:00:00     427546.46336   95545.127143    82339.820714   \n",
              " \n",
              "                      M1_MA_20_lag_2  M1_RSI_14_lag_2  \\\n",
              " timestamp                                              \n",
              " 2020-05-12 00:00:00        7063.916        44.728795   \n",
              " 2020-05-12 04:00:00        7063.916        44.728795   \n",
              " 2020-05-12 08:00:00        7063.916        44.728795   \n",
              " 2020-05-12 12:00:00        7063.916        44.728795   \n",
              " 2020-05-12 16:00:00        7063.916        44.728795   \n",
              " ...                             ...              ...   \n",
              " 2025-09-18 08:00:00       73421.401        70.031673   \n",
              " 2025-09-18 12:00:00       73421.401        70.031673   \n",
              " 2025-09-18 16:00:00       73421.401        70.031673   \n",
              " 2025-09-18 20:00:00       73421.401        70.031673   \n",
              " 2025-09-19 00:00:00       73421.401        70.031673   \n",
              " \n",
              "                      M1_conversion_line_lag_2  M1_baseline_lag_2  \\\n",
              " timestamp                                                          \n",
              " 2020-05-12 00:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 04:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 08:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 12:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 16:00:00                   10202.5           10166.25   \n",
              " ...                                       ...                ...   \n",
              " 2025-09-18 08:00:00                   85463.0            68390.0   \n",
              " 2025-09-18 12:00:00                   85463.0            68390.0   \n",
              " 2025-09-18 16:00:00                   85463.0            68390.0   \n",
              " 2025-09-18 20:00:00                   85463.0            68390.0   \n",
              " 2025-09-19 00:00:00                   85463.0            68390.0   \n",
              " \n",
              "                     M1_lagging_span_lag_2  \n",
              " timestamp                                  \n",
              " 2020-05-12 00:00:00              13716.36  \n",
              " 2020-05-12 04:00:00              13716.36  \n",
              " 2020-05-12 08:00:00              13716.36  \n",
              " 2020-05-12 12:00:00              13716.36  \n",
              " 2020-05-12 16:00:00              13716.36  \n",
              " ...                                   ...  \n",
              " 2025-09-18 08:00:00              29233.21  \n",
              " 2025-09-18 12:00:00              29233.21  \n",
              " 2025-09-18 16:00:00              29233.21  \n",
              " 2025-09-18 20:00:00              29233.21  \n",
              " 2025-09-19 00:00:00              29233.21  \n",
              " \n",
              " [11737 rows x 411 columns],\n",
              "                      target\n",
              " timestamp                  \n",
              " 2020-05-12 00:00:00       1\n",
              " 2020-05-12 04:00:00       1\n",
              " 2020-05-12 08:00:00       1\n",
              " 2020-05-12 12:00:00       1\n",
              " 2020-05-12 16:00:00       1\n",
              " ...                     ...\n",
              " 2025-09-18 08:00:00       1\n",
              " 2025-09-18 12:00:00       1\n",
              " 2025-09-18 16:00:00       1\n",
              " 2025-09-18 20:00:00       1\n",
              " 2025-09-19 00:00:00       1\n",
              " \n",
              " [11737 rows x 1 columns])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def save_focused_feature_sets_complete(A0, A1, A2, A3, A4, h4_full, train_start='2020-05-12', test_end='2025-09-19'):\n",
        "    \"\"\"Save focused feature sets with correct target variable creation\"\"\"\n",
        "    \n",
        "    print(\"ðŸ’¾ Saving focused feature sets...\")\n",
        "    \n",
        "    # Create features directory\n",
        "    features_dir = Path('../features')\n",
        "    features_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Filter feature sets to focused period\n",
        "    def filter_focused_period(data, start_date, end_date):\n",
        "        return data[(data.index >= start_date) & (data.index <= end_date)]\n",
        "    \n",
        "    # Save feature sets\n",
        "    A0_focused = filter_focused_period(A0, train_start, test_end)\n",
        "    A1_focused = filter_focused_period(A1, train_start, test_end)\n",
        "    A2_focused = filter_focused_period(A2, train_start, test_end)\n",
        "    A3_focused = filter_focused_period(A3, train_start, test_end)\n",
        "    A4_focused = filter_focused_period(A4, train_start, test_end)\n",
        "    \n",
        "    # Create target variable using FULL H4 data\n",
        "    y_focused = create_target_variable_first_threshold_vectorized(h4_full, train_start, test_end)\n",
        "    \n",
        "    # Save all files\n",
        "    A0_focused.to_parquet(features_dir / 'A0.parquet')\n",
        "    A1_focused.to_parquet(features_dir / 'A1.parquet')\n",
        "    A2_focused.to_parquet(features_dir / 'A2.parquet')\n",
        "    A3_focused.to_parquet(features_dir / 'A3.parquet')\n",
        "    A4_focused.to_parquet(features_dir / 'A4.parquet')\n",
        "    y_focused.to_parquet(features_dir / 'y.parquet')\n",
        "    \n",
        "    print(\"ðŸŽ‰ All feature sets saved successfully!\")\n",
        "    return A0_focused, A1_focused, A2_focused, A3_focused, A4_focused, y_focused\n",
        "\n",
        "# Run the complete save function\n",
        "save_focused_feature_sets_complete(A0, A1, A2, A3, A4, h4_full, train_start='2020-05-12', test_end='2025-09-19')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_saved_feature_sets(features_dir='../features'):\n",
        "    \"\"\"\n",
        "    Validate that all feature sets and target variable were saved correctly\n",
        "    \n",
        "    Args:\n",
        "        features_dir: Path to features directory\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"ðŸ” Validating Saved Feature Sets...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check if features directory exists\n",
        "    features_path = Path(features_dir)\n",
        "    if not features_path.exists():\n",
        "        print(\"âŒ Features directory not found!\")\n",
        "        return\n",
        "    \n",
        "    # Expected files\n",
        "    expected_files = ['A0.parquet', 'A1.parquet', 'A2.parquet', 'A3.parquet', 'A4.parquet', 'y.parquet']\n",
        "    \n",
        "    print(\"ðŸ“ File Existence Check:\")\n",
        "    for file in expected_files:\n",
        "        file_path = features_path / file\n",
        "        if file_path.exists():\n",
        "            print(f\"  âœ… {file} - Found\")\n",
        "        else:\n",
        "            print(f\"  âŒ {file} - Missing!\")\n",
        "    \n",
        "    print(\"\\nðŸ“Š Data Validation:\")\n",
        "    \n",
        "    # Load and validate each file\n",
        "    for file in expected_files:\n",
        "        file_path = features_path / file\n",
        "        if not file_path.exists():\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\nðŸ” Validating {file}:\")\n",
        "        \n",
        "        try:\n",
        "            # Load data\n",
        "            data = pd.read_parquet(file_path)\n",
        "            \n",
        "            # Basic info\n",
        "            print(f\"  ðŸ“ Shape: {data.shape[0]} records Ã— {data.shape[1]} features\")\n",
        "            print(f\"  ðŸ“… Period: {data.index[0]} to {data.index[-1]}\")\n",
        "            \n",
        "            # Check for missing values\n",
        "            missing_count = data.isnull().sum().sum()\n",
        "            total_cells = data.shape[0] * data.shape[1]\n",
        "            missing_percentage = (missing_count / total_cells) * 100 if total_cells > 0 else 0\n",
        "            \n",
        "            if missing_count == 0:\n",
        "                print(f\"  âœ… Missing values: {missing_count} (0.00%)\")\n",
        "            else:\n",
        "                print(f\"  âš ï¸ Missing values: {missing_count} ({missing_percentage:.2f}%)\")\n",
        "                \n",
        "                # Show which columns have missing values\n",
        "                missing_cols = data.isnull().sum()\n",
        "                missing_cols = missing_cols[missing_cols > 0]\n",
        "                if len(missing_cols) > 0:\n",
        "                    print(f\"    Columns with missing values:\")\n",
        "                    for col, count in missing_cols.items():\n",
        "                        print(f\"      {col}: {count} missing\")\n",
        "            \n",
        "            # Check data types\n",
        "            print(f\"  ðŸ“‹ Data types: {data.dtypes.value_counts().to_dict()}\")\n",
        "            \n",
        "            # Check for infinite values\n",
        "            inf_count = np.isinf(data.select_dtypes(include=[np.number])).sum().sum()\n",
        "            if inf_count == 0:\n",
        "                print(f\"  âœ… Infinite values: {inf_count}\")\n",
        "            else:\n",
        "                print(f\"  âš ï¸ Infinite values: {inf_count}\")\n",
        "            \n",
        "            # Specific validation for target variable\n",
        "            if file == 'y.parquet':\n",
        "                print(f\"  ðŸŽ¯ Target variable validation:\")\n",
        "                print(f\"    Unique values: {data['target'].unique()}\")\n",
        "                print(f\"    Value counts: {data['target'].value_counts().to_dict()}\")\n",
        "                print(f\"    Sell percentage: {data['target'].mean()*100:.2f}%\")\n",
        "            \n",
        "            # Specific validation for feature sets\n",
        "            if file.startswith('A'):\n",
        "                print(f\"  ðŸ”¢ Feature set validation:\")\n",
        "                print(f\"    Feature count: {len(data.columns)}\")\n",
        "                print(f\"    Sample features: {list(data.columns[:5])}\")\n",
        "                \n",
        "                # Check for expected feature counts\n",
        "                expected_counts = {'A0': 19, 'A1': 38, 'A2': 56, 'A3': 67, 'A4': 416}\n",
        "                if file.replace('.parquet', '') in expected_counts:\n",
        "                    expected = expected_counts[file.replace('.parquet', '')]\n",
        "                    actual = len(data.columns)\n",
        "                    if actual == expected:\n",
        "                        print(f\"    âœ… Feature count matches expected: {actual}\")\n",
        "                    else:\n",
        "                        print(f\"    âš ï¸ Feature count mismatch: {actual} (expected {expected})\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ Error loading {file}: {e}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"ðŸŽ‰ Validation Complete!\")\n",
        "\n",
        "# Run validation\n",
        "validate_saved_feature_sets('../features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.2 Implementation Complete! âœ…\n",
        "\n",
        "### **Summary of CORRECTED Implementation**\n",
        "\n",
        "**Approach**: Calculate everything together, split on save step.\n",
        "\n",
        "**Steps Completed**:\n",
        "1. âœ… **Load Full Data**: Complete dataset including buffer (2020-03-01 to 2025-10-19)\n",
        "2. âœ… **Technical Indicators**: Calculated all 19 indicators per timeframe on full data\n",
        "3. âœ… **Feature Sets A0â†’A3**: Created incremental feature sets with proper temporal alignment\n",
        "4. âœ… **Historical Lag Features**: Created lag features using full data for complete historical context\n",
        "5. âœ… **A4 Feature Set**: Combined A3 + all historical lags (437 features)\n",
        "6. âœ… **Data Validation**: Verified feature counts and missing values\n",
        "7. âœ… **Save Clean Data**: Split clean period (2020-05-12 to 2025-09-19) only at save step\n",
        "\n",
        "### **Key Fixes Applied**:\n",
        "1. **Full Data Calculations**: All indicators and lags calculated on complete dataset\n",
        "2. **Proper Temporal Alignment**: Enhanced alignment logic with timeframe-specific offsets\n",
        "3. **Complete Historical Context**: W1 data from 2020-05-04, M1 data from 2020-05-01\n",
        "4. **No Missing Data**: Full historical context for all lag features\n",
        "5. **Clean Final Output**: Buffer data used for calculations but not stored\n",
        "\n",
        "### **Temporal Alignment Logic**:\n",
        "- **H4 timestamp 2020-05-11 00:00:00** (candle closed at 2020-05-11 04:00:00):\n",
        "  - **D1 data**: `base_timestamp - 1d` â†’ Use 2020-05-10 00:00:00 (previous day's close) âœ…\n",
        "  - **W1 data**: `base_timestamp - 1w` â†’ Use 2020-05-04 00:00:00 (previous week's close) âœ…\n",
        "  - **M1 data**: `base_timestamp - 1m` â†’ Use 2020-04-11 00:00:00 (previous month's close) âœ…\n",
        "- **Uses timeframe-specific offsets** to ensure proper temporal alignment\n",
        "- **Ensures no future data leakage** and realistic trading scenarios\n",
        "\n",
        "### **Expected Outputs**\n",
        "- **A0.parquet**: 19 features (H4 only)\n",
        "- **A1.parquet**: 38 features (H4 + D1)\n",
        "- **A2.parquet**: 57 features (H4 + D1 + W1)\n",
        "- **A3.parquet**: 76 features (H4 + D1 + W1 + M1)\n",
        "- **A4.parquet**: 437 features (A3 + all historical lags)\n",
        "\n",
        "### **Next Steps**\n",
        "- **Step 3**: Train/test split based on timeline\n",
        "- **Step 4**: Ablation Study experiments (A0â†’A4_Pruned)\n",
        "- **Step 5**: Results analysis and RQ answers\n",
        "\n",
        "**Ready to proceed to Step 3!** ðŸš€\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "csml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
