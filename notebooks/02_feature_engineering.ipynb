{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BTC Feature Engineering - CORRECTED APPROACH\n",
        "\n",
        "## Overview\n",
        "This notebook implements the CORRECTED approach: Calculate everything together, split on save.\n",
        "\n",
        "**Key Changes:**\n",
        "1. Load full data (including buffer) for complete calculations\n",
        "2. Calculate all indicators and features on full data\n",
        "3. Create feature sets A0→A4 with proper temporal alignment\n",
        "4. Split clean data only at save step\n",
        "\n",
        "**Benefits:**\n",
        "- Complete historical context for all calculations\n",
        "- Proper temporal alignment with full data\n",
        "- No missing data for lag features\n",
        "- Clean final output without buffer data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import talib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "train_start='2020-05-12'\n",
        "test_end='2025-09-19'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Full data loaded (including buffer):\n",
            "  H4: 12368 records (2020-03-01 00:00:00 to 2025-10-22 04:00:00)\n",
            "  D1: 2146 records (2019-12-08 00:00:00 to 2025-10-22 00:00:00)\n",
            "  W1: 350 records (2019-02-11 00:00:00 to 2025-10-20 00:00:00)\n",
            "  M1: 95 records (2017-12-01 00:00:00 to 2025-10-01 00:00:00)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load Full Data (Including Buffer) for Complete Calculations\n",
        "def load_full_data():\n",
        "    \"\"\"Load full data including buffer for complete calculations\"\"\"\n",
        "    \n",
        "    # Load full data\n",
        "    h4_full = pd.read_parquet('../data_collection/data/btc_4h_20251022.parquet')\n",
        "    d1_full = pd.read_parquet('../data_collection/data/btc_1d_20251022.parquet')\n",
        "    w1_full = pd.read_parquet('../data_collection/data/btc_1w_20251022.parquet')\n",
        "    m1_full = pd.read_parquet('../data_collection/data/btc_1M_20251022.parquet')\n",
        "    \n",
        "    # Ensure datetime index\n",
        "    for df in [h4_full, d1_full, w1_full, m1_full]:\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "    \n",
        "    print(f\"📊 Full data loaded (including buffer):\")\n",
        "    print(f\"  H4: {len(h4_full)} records ({h4_full.index[0]} to {h4_full.index[-1]})\")\n",
        "    print(f\"  D1: {len(d1_full)} records ({d1_full.index[0]} to {d1_full.index[-1]})\")\n",
        "    print(f\"  W1: {len(w1_full)} records ({w1_full.index[0]} to {w1_full.index[-1]})\")\n",
        "    print(f\"  M1: {len(m1_full)} records ({m1_full.index[0]} to {m1_full.index[-1]})\")\n",
        "    \n",
        "    return h4_full, d1_full, w1_full, m1_full\n",
        "\n",
        "# Load full data for complete calculations\n",
        "h4_full, d1_full, w1_full, m1_full = load_full_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Technical Indicator Functions\n",
        "def extract_ohlcv_features(data):\n",
        "    \"\"\"Extract OHLCV features (5 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    features['open'] = data['open']\n",
        "    features['high'] = data['high']\n",
        "    features['low'] = data['low']\n",
        "    features['close'] = data['close']\n",
        "    features['volume'] = data['volume']\n",
        "    return features\n",
        "\n",
        "def calculate_moving_averages(data, periods=[7, 14, 20, 60, 120]):\n",
        "    \"\"\"Calculate moving averages using CLOSE prices (5 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    for period in periods:\n",
        "        features[f'MA_{period}'] = talib.SMA(data['close'], timeperiod=period)\n",
        "    return features\n",
        "\n",
        "def calculate_rsi(data, period=14):\n",
        "    \"\"\"Calculate RSI using CLOSE prices (1 feature)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    features['RSI_14'] = talib.RSI(data['close'], timeperiod=period)\n",
        "    return features\n",
        "\n",
        "def calculate_macd(data, fast=12, slow=26, signal=9):\n",
        "    \"\"\"Calculate MACD line, signal, and histogram (3 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    macd_line, macd_signal, macd_hist = talib.MACD(data['close'], \n",
        "                                                   fastperiod=fast, \n",
        "                                                   slowperiod=slow, \n",
        "                                                   signalperiod=signal)\n",
        "    features['MACD_line'] = macd_line\n",
        "    features['MACD_signal'] = macd_signal\n",
        "    features['MACD_hist'] = macd_hist\n",
        "    return features\n",
        "\n",
        "def calculate_ichimoku(data):\n",
        "    \"\"\"Calculate Ichimoku Cloud components (5 features)\"\"\"\n",
        "    features = pd.DataFrame(index=data.index)\n",
        "    \n",
        "    # Tenkan-sen (Conversion Line)\n",
        "    high_9 = data['high'].rolling(window=9).max()\n",
        "    low_9 = data['low'].rolling(window=9).min()\n",
        "    features['conversion_line'] = (high_9 + low_9) / 2\n",
        "    \n",
        "    # Kijun-sen (Baseline)\n",
        "    high_26 = data['high'].rolling(window=26).max()\n",
        "    low_26 = data['low'].rolling(window=26).min()\n",
        "    features['baseline'] = (high_26 + low_26) / 2\n",
        "    \n",
        "    # Senkou Span A (Leading Span A)\n",
        "    features['leading_span_A'] = (features['conversion_line'] + features['baseline']) / 2\n",
        "    \n",
        "    # Senkou Span B (Leading Span B)\n",
        "    high_52 = data['high'].rolling(window=52).max()\n",
        "    low_52 = data['low'].rolling(window=52).min()\n",
        "    features['leading_span_B'] = (high_52 + low_52) / 2\n",
        "    \n",
        "    # Chikou Span (Lagging Span) - Current close compared to 26 periods ago\n",
        "    features['lagging_span'] = data['close'].shift(26)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def calculate_all_indicators(data, timeframe_name):\n",
        "    \"\"\"Calculate all 19 indicators for a timeframe\"\"\"\n",
        "    print(f\"Calculating indicators for {timeframe_name}...\")\n",
        "    \n",
        "    # Combine all indicator functions\n",
        "    ohlcv = extract_ohlcv_features(data)\n",
        "    ma = calculate_moving_averages(data)\n",
        "    rsi = calculate_rsi(data)\n",
        "    macd = calculate_macd(data)\n",
        "    ichimoku = calculate_ichimoku(data)\n",
        "    \n",
        "    # Combine all features\n",
        "    all_features = pd.concat([ohlcv, ma, rsi, macd, ichimoku], axis=1)\n",
        "    \n",
        "    # Add timeframe prefix to column names\n",
        "    all_features.columns = [f\"{timeframe_name}_{col}\" for col in all_features.columns]\n",
        "    \n",
        "    print(f\"✅ {timeframe_name}: {len(all_features.columns)} features created\")\n",
        "    return all_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Calculating indicators on full data (including buffer)...\n",
            "Calculating indicators for H4...\n",
            "✅ H4: 19 features created\n",
            "Calculating indicators for D1...\n",
            "✅ D1: 19 features created\n",
            "Calculating indicators for W1...\n",
            "✅ W1: 19 features created\n",
            "Calculating indicators for M1...\n",
            "✅ M1: 19 features created\n",
            "✅ All indicators calculated on full data\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Calculate Indicators on Full Data (Including Buffer)\n",
        "def calculate_indicators_on_full_data(h4_full, d1_full, w1_full, m1_full):\n",
        "    \"\"\"Calculate indicators using full data to ensure proper calculations\"\"\"\n",
        "    \n",
        "    print(\"🔄 Calculating indicators on full data (including buffer)...\")\n",
        "    \n",
        "    # Calculate indicators on full data\n",
        "    h4_indicators_full = calculate_all_indicators(h4_full, 'H4')\n",
        "    d1_indicators_full = calculate_all_indicators(d1_full, 'D1')\n",
        "    w1_indicators_full = calculate_all_indicators(w1_full, 'W1')\n",
        "    m1_indicators_full = calculate_all_indicators(m1_full, 'M1')\n",
        "    \n",
        "    print(\"✅ All indicators calculated on full data\")\n",
        "    return h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full\n",
        "\n",
        "# Calculate indicators on full data\n",
        "h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full = calculate_indicators_on_full_data(\n",
        "    h4_full, d1_full, w1_full, m1_full\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_previous_month_timestamp(timestamp):\n",
        "    \"\"\"\n",
        "    Get the 10th day of the previous month\n",
        "    Simple and handles all edge cases!\n",
        "    \"\"\"\n",
        "    dt = pd.to_datetime(timestamp)\n",
        "    \n",
        "    # Get previous month\n",
        "    if dt.month == 1:\n",
        "        prev_month = dt.replace(year=dt.year-1, month=12, day=10)\n",
        "    else:\n",
        "        prev_month = dt.replace(month=dt.month-1, day=10)\n",
        "    \n",
        "    return prev_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧹 Removing problematic indicators...\n",
            "✅ Removed W1_MA_120 (needs 2.3 years of data)\n",
            "✅ Removed M1_MA_120 (needs 5-10 years of data)\n",
            "✅ Removed M1_MA_60 (needs 5-10 years of data)\n",
            "✅ Removed M1_leading_span_A (needs 5-10 years of data)\n",
            "✅ Removed M1_leading_span_B (needs 5-10 years of data)\n",
            "✅ Removed M1_MACD_line (needs 5-10 years of data)\n",
            "✅ Removed M1_MACD_signal (needs 5-10 years of data)\n",
            "✅ Removed M1_MACD_hist (needs 5-10 years of data)\n",
            "📊 Cleaned indicators:\n",
            "  H4: 19 features (no changes)\n",
            "  D1: 19 features (no changes)\n",
            "  W1: 18 features (removed 1)\n",
            "  M1: 12 features (removed 7)\n"
          ]
        }
      ],
      "source": [
        "# Step 3.5: Remove Problematic Indicators After Calculation\n",
        "def remove_problematic_indicators(h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full):\n",
        "    \"\"\"\n",
        "    Remove indicators that cannot be calculated with available data\n",
        "    - W1: Remove 120 MA (needs 2.3 years of data)\n",
        "    - M1: Remove 120 MA, 60 MA, leading_span_A, leading_span_B (need 5-10 years of data)\n",
        "    \"\"\"\n",
        "    print(\"🧹 Removing problematic indicators...\")\n",
        "    \n",
        "    # W1: Remove 120 MA\n",
        "    w1_indicators_clean = w1_indicators_full.copy()\n",
        "    if 'W1_MA_120' in w1_indicators_clean.columns:\n",
        "        w1_indicators_clean = w1_indicators_clean.drop('W1_MA_120', axis=1)\n",
        "        print(\"✅ Removed W1_MA_120 (needs 2.3 years of data)\")\n",
        "    \n",
        "    # M1: Remove 120 MA, 60 MA, leading_span_A, leading_span_B\n",
        "    m1_indicators_clean = m1_indicators_full.copy()\n",
        "    problematic_m1_cols = ['M1_MA_120', 'M1_MA_60', 'M1_leading_span_A', 'M1_leading_span_B', 'M1_MACD_line', 'M1_MACD_signal', 'M1_MACD_hist']\n",
        "    \n",
        "    for col in problematic_m1_cols:\n",
        "        if col in m1_indicators_clean.columns:\n",
        "            m1_indicators_clean = m1_indicators_clean.drop(col, axis=1)\n",
        "            print(f\"✅ Removed {col} (needs 5-10 years of data)\")\n",
        "    \n",
        "    print(f\"📊 Cleaned indicators:\")\n",
        "    print(f\"  H4: {len(h4_indicators_full.columns)} features (no changes)\")\n",
        "    print(f\"  D1: {len(d1_indicators_full.columns)} features (no changes)\")\n",
        "    print(f\"  W1: {len(w1_indicators_clean.columns)} features (removed 1)\")\n",
        "    print(f\"  M1: {len(m1_indicators_clean.columns)} features (removed 7)\")\n",
        "    \n",
        "    return h4_indicators_full, d1_indicators_full, w1_indicators_clean, m1_indicators_clean\n",
        "\n",
        "# Remove problematic indicators\n",
        "h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean = remove_problematic_indicators(\n",
        "    h4_indicators_full, d1_indicators_full, w1_indicators_full, m1_indicators_full\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2020-06-01 00:00:00 2025-09-01 00:00:00\n",
            "2017-12-01 00:00:00 2025-10-01 00:00:00\n",
            "2017-12-01 00:00:00 2025-10-01 00:00:00\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "m1_focused = m1_indicators_clean[(m1_indicators_clean.index >= train_start)\n",
        "                                 & (m1_indicators_clean.index <= test_end)]\n",
        "\n",
        "print(m1_focused.isnull().sum().sum())\n",
        "print(m1_focused.index.min(), m1_focused.index.max())\n",
        "print(m1_indicators_clean.index.min(), m1_indicators_clean.index.max())\n",
        "print(m1_full.index.min(), m1_full.index.max())\n",
        "print(m1_full.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Temporal Alignment Functions (CORRECTED VERSION)\n",
        "def align_timeframe_data(base_data, target_data, base_timeframe, target_timeframe):\n",
        "    \"\"\"\n",
        "    Align target timeframe data with base timeframe data using proper temporal alignment\n",
        "    \n",
        "    Args:\n",
        "        base_data: H4 data (base timeframe)\n",
        "        target_data: D1/W1/M1 data (target timeframe)\n",
        "        base_timeframe: 'H4'\n",
        "        target_timeframe: 'D1', 'W1', 'M1', 'D1_lags', 'W1_lags', 'M1_lags'\n",
        "    \n",
        "    Returns:\n",
        "        aligned_data: Target data aligned with base data timestamps\n",
        "    \"\"\"\n",
        "    print(f\"🔄 Aligning {target_timeframe} data with {base_timeframe} timestamps...\")\n",
        "    \n",
        "    # Define timeframe offsets - ADD LAG SUPPORT\n",
        "    timeframe_offsets = {\n",
        "        'D1': pd.Timedelta(days=1),\n",
        "        'W1': pd.Timedelta(weeks=1),\n",
        "        'M1':'previous_month_10th',  # Approximate month\n",
        "        # Add lag support\n",
        "        'D1_lags': pd.Timedelta(days=1),\n",
        "        'W1_lags': pd.Timedelta(weeks=1),\n",
        "        'M1_lags': 'previous_month_10th'\n",
        "    }\n",
        "    \n",
        "    aligned_data = pd.DataFrame(index=base_data.index, columns=target_data.columns)\n",
        "    \n",
        "    for base_timestamp in base_data.index:\n",
        "        # Calculate the cutoff time\n",
        "        if timeframe_offsets[target_timeframe] == 'previous_month_10th':\n",
        "            # Use our new function for month alignment\n",
        "            cutoff_time = get_previous_month_timestamp(base_timestamp)\n",
        "        else:\n",
        "            # Use regular timedelta for other timeframes\n",
        "            offset = timeframe_offsets[target_timeframe]\n",
        "            cutoff_time = base_timestamp - offset\n",
        "        \n",
        "        # Find target data that is <= cutoff_time (previous completed data)\n",
        "        available_target_data = target_data[target_data.index <= cutoff_time]\n",
        "        \n",
        "        if len(available_target_data) > 0:\n",
        "            # Use the most recent available data (previous completed)\n",
        "            latest_target_data = available_target_data.iloc[-1]\n",
        "            aligned_data.loc[base_timestamp] = latest_target_data\n",
        "        else:\n",
        "            # If no data available, fill with NaN\n",
        "            aligned_data.loc[base_timestamp] = np.nan\n",
        "    \n",
        "    print(f\"✅ {target_timeframe} data aligned: {len(aligned_data.columns)} features, {len(aligned_data)} records\")\n",
        "    return aligned_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Aligning D1 data with H4 timestamps...\n",
            "✅ D1 data aligned: 19 features, 12368 records\n",
            "🔄 Aligning W1 data with H4 timestamps...\n",
            "✅ W1 data aligned: 18 features, 12368 records\n",
            "🔄 Aligning M1 data with H4 timestamps...\n",
            "✅ M1 data aligned: 12 features, 12368 records\n",
            "✅ Feature sets A0→A3 created with cleaned indicators:\n",
            "  A0: 19 features, 12368 records\n",
            "  A1: 38 features, 12368 records\n",
            "  A2: 56 features, 12368 records\n",
            "  A3: 68 features, 12368 records\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Create Feature Sets A0→A3 with Cleaned Indicators\n",
        "def create_feature_sets_with_cleaned_indicators(h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean):\n",
        "    \"\"\"Create feature sets A0→A3 using cleaned indicators (no problematic indicators)\"\"\"\n",
        "    \n",
        "    # A0: H4 indicators only\n",
        "    A0 = h4_indicators_clean.copy()\n",
        "    \n",
        "    # A1: H4 + D1 indicators - Align D1 with H4 timestamps\n",
        "    d1_aligned = align_timeframe_data(A0, d1_indicators_clean, 'H4', 'D1')\n",
        "    A1 = pd.concat([h4_indicators_clean, d1_aligned], axis=1)\n",
        "    \n",
        "    # A2: H4 + D1 + W1 indicators - Align W1 with H4 timestamps\n",
        "    w1_aligned = align_timeframe_data(A0, w1_indicators_clean, 'H4', 'W1')\n",
        "    A2 = pd.concat([h4_indicators_clean, d1_aligned, w1_aligned], axis=1)\n",
        "    \n",
        "    # A3: H4 + D1 + W1 + M1 indicators - Align M1 with H4 timestamps\n",
        "    m1_aligned = align_timeframe_data(A0, m1_indicators_clean, 'H4', 'M1')\n",
        "    A3 = pd.concat([h4_indicators_clean, d1_aligned, w1_aligned, m1_aligned], axis=1)\n",
        "    \n",
        "    print(f\"✅ Feature sets A0→A3 created with cleaned indicators:\")\n",
        "    print(f\"  A0: {len(A0.columns)} features, {len(A0)} records\")\n",
        "    print(f\"  A1: {len(A1.columns)} features, {len(A1)} records\")\n",
        "    print(f\"  A2: {len(A2.columns)} features, {len(A2)} records\")\n",
        "    print(f\"  A3: {len(A3.columns)} features, {len(A3)} records\")\n",
        "    \n",
        "    return A0, A1, A2, A3\n",
        "\n",
        "# Create feature sets with cleaned indicators\n",
        "A0, A1, A2, A3 = create_feature_sets_with_cleaned_indicators(\n",
        "    h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Feature Set Validation:\n",
            "A0_focused.isnull().sum().sum(): 0\n",
            "A1_focused.isnull().sum().sum(): 0\n",
            "A2_focused.isnull().sum().sum(): 0\n",
            "A3_focused.isnull().sum().sum(): 0\n"
          ]
        }
      ],
      "source": [
        "def validate_A0_to_A3(A0, A1, A2, A3):\n",
        "    \"\"\"Validate feature sets A0→A3\"\"\"\n",
        "    print(\"🔍 Feature Set Validation:\")\n",
        "    train_start = '2020-05-12'\n",
        "    test_end = '2025-09-19'\n",
        "\n",
        "    A0_focused = A0[(A0.index >= train_start) & (A0.index <= test_end)]\n",
        "    A1_focused = A1[(A1.index >= train_start) & (A1.index <= test_end)]\n",
        "    A2_focused = A2[(A2.index >= train_start) & (A2.index <= test_end)]\n",
        "    A3_focused = A3[(A3.index >= train_start) & (A3.index <= test_end)]\n",
        "\n",
        "    print(\n",
        "        f\"A0_focused.isnull().sum().sum(): {A0_focused.isnull().sum().sum()}\")\n",
        "    print(\n",
        "        f\"A1_focused.isnull().sum().sum(): {A1_focused.isnull().sum().sum()}\")\n",
        "    print(\n",
        "        f\"A2_focused.isnull().sum().sum(): {A2_focused.isnull().sum().sum()}\")\n",
        "    print(\n",
        "        f\"A3_focused.isnull().sum().sum(): {A3_focused.isnull().sum().sum()}\")\n",
        "\n",
        "validate_A0_to_A3(A0, A1, A2, A3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏰ Creating historical lag features using full data (including buffer)...\n",
            "✅ H4 lags: 114 features created\n",
            "✅ D1 lags: 133 features created\n",
            "✅ W1 lags: 72 features created\n",
            "✅ M1 lags: 24 features created\n",
            "✅ All lag features created using full data:\n",
            "  H4 lags: 114 features, 12368 records\n",
            "  D1 lags: 133 features, 2146 records\n",
            "  W1 lags: 72 features, 350 records\n",
            "  M1 lags: 24 features, 95 records\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Create Historical Lag Features (Using Full Data with Buffer)\n",
        "def create_lag_features(indicators_full, timeframe_name, lag_periods):\n",
        "    \"\"\"Create historical lag features for a timeframe using full data (including buffer)\"\"\"\n",
        "    lag_features = pd.DataFrame(index=indicators_full.index)\n",
        "    \n",
        "    for lag in lag_periods:\n",
        "        for col in indicators_full.columns:\n",
        "            lag_features[f\"{col}_lag_{lag}\"] = indicators_full[col].shift(lag)\n",
        "    \n",
        "    print(f\"✅ {timeframe_name} lags: {len(lag_features.columns)} features created\")\n",
        "    return lag_features\n",
        "\n",
        "def create_all_lag_features_with_buffer(h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean):\n",
        "    \"\"\"Create historical lag features for all timeframes using full data (including buffer)\"\"\"\n",
        "    \n",
        "    print(\"⏰ Creating historical lag features using full data (including buffer)...\")\n",
        "    \n",
        "    # H4 lags: t-1 to t-6 (6 lags)\n",
        "    h4_lags_full = create_lag_features(h4_indicators_clean, 'H4', range(1, 7))\n",
        "    \n",
        "    # D1 lags: t-1 to t-7 (7 lags)\n",
        "    d1_lags_full = create_lag_features(d1_indicators_clean, 'D1', range(1, 8))\n",
        "    \n",
        "    # W1 lags: t-1 to t-4 (4 lags)\n",
        "    w1_lags_full = create_lag_features(w1_indicators_clean, 'W1', range(1, 5))\n",
        "    \n",
        "    # M1 lags: t-1 to t-2 (2 lags)\n",
        "    m1_lags_full = create_lag_features(m1_indicators_clean, 'M1', range(1, 3))\n",
        "    \n",
        "    print(f\"✅ All lag features created using full data:\")\n",
        "    print(f\"  H4 lags: {len(h4_lags_full.columns)} features, {len(h4_lags_full)} records\")\n",
        "    print(f\"  D1 lags: {len(d1_lags_full.columns)} features, {len(d1_lags_full)} records\")\n",
        "    print(f\"  W1 lags: {len(w1_lags_full.columns)} features, {len(w1_lags_full)} records\")\n",
        "    print(f\"  M1 lags: {len(m1_lags_full.columns)} features, {len(m1_lags_full)} records\")\n",
        "    \n",
        "    return h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full\n",
        "\n",
        "# Create historical lag features using full data (including buffer)\n",
        "h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full = create_all_lag_features_with_buffer(\n",
        "    h4_indicators_clean, d1_indicators_clean, w1_indicators_clean, m1_indicators_clean\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2020-05-12 00:00:00 2025-09-19 00:00:00\n",
            "0\n",
            "2020-05-12 00:00:00 2025-09-19 00:00:00\n",
            "0\n",
            "2020-05-18 00:00:00 2025-09-15 00:00:00\n",
            "0\n",
            "2020-06-01 00:00:00 2025-09-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "h4_lags_focused=h4_lags_full[(h4_lags_full.index >= train_start) & (h4_lags_full.index <= test_end)]\n",
        "print(h4_lags_focused.isnull().sum().sum())\n",
        "print(h4_lags_focused.index.min(), h4_lags_focused.index.max())\n",
        "\n",
        "d1_lags_focused = d1_lags_full[(d1_lags_full.index >= train_start)\n",
        "                               & (d1_lags_full.index <= test_end)]\n",
        "print(d1_lags_focused.isnull().sum().sum())\n",
        "print(d1_lags_focused.index.min(), d1_lags_focused.index.max())\n",
        "\n",
        "w1_lags_focused = w1_lags_full[(w1_lags_full.index >= train_start)\n",
        "                              & (w1_lags_full.index <= test_end)]\n",
        "print(w1_lags_focused.isnull().sum().sum())\n",
        "print(w1_lags_focused.index.min(), w1_lags_focused.index.max())\n",
        "\n",
        "m1_lags_focused = m1_lags_full[(m1_lags_full.index >= train_start)\n",
        "                              & (m1_lags_full.index <= test_end)]\n",
        "print(m1_lags_focused.isnull().sum().sum())\n",
        "print(m1_lags_focused.index.min(), m1_lags_focused.index.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            D1_open_lag_1  D1_high_lag_1  D1_low_lag_1  D1_close_lag_1  \\\n",
            "timestamp                                                                \n",
            "2020-05-12          False          False         False           False   \n",
            "2020-05-13          False          False         False           False   \n",
            "2020-05-14          False          False         False           False   \n",
            "2020-05-15          False          False         False           False   \n",
            "2020-05-16          False          False         False           False   \n",
            "\n",
            "            D1_volume_lag_1  D1_MA_7_lag_1  D1_MA_14_lag_1  D1_MA_20_lag_1  \\\n",
            "timestamp                                                                    \n",
            "2020-05-12            False          False           False           False   \n",
            "2020-05-13            False          False           False           False   \n",
            "2020-05-14            False          False           False           False   \n",
            "2020-05-15            False          False           False           False   \n",
            "2020-05-16            False          False           False           False   \n",
            "\n",
            "            D1_MA_60_lag_1  D1_MA_120_lag_1  ...  D1_MA_120_lag_7  \\\n",
            "timestamp                                    ...                    \n",
            "2020-05-12           False            False  ...            False   \n",
            "2020-05-13           False            False  ...            False   \n",
            "2020-05-14           False            False  ...            False   \n",
            "2020-05-15           False            False  ...            False   \n",
            "2020-05-16           False            False  ...            False   \n",
            "\n",
            "            D1_RSI_14_lag_7  D1_MACD_line_lag_7  D1_MACD_signal_lag_7  \\\n",
            "timestamp                                                               \n",
            "2020-05-12            False               False                 False   \n",
            "2020-05-13            False               False                 False   \n",
            "2020-05-14            False               False                 False   \n",
            "2020-05-15            False               False                 False   \n",
            "2020-05-16            False               False                 False   \n",
            "\n",
            "            D1_MACD_hist_lag_7  D1_conversion_line_lag_7  D1_baseline_lag_7  \\\n",
            "timestamp                                                                     \n",
            "2020-05-12               False                     False              False   \n",
            "2020-05-13               False                     False              False   \n",
            "2020-05-14               False                     False              False   \n",
            "2020-05-15               False                     False              False   \n",
            "2020-05-16               False                     False              False   \n",
            "\n",
            "            D1_leading_span_A_lag_7  D1_leading_span_B_lag_7  \\\n",
            "timestamp                                                      \n",
            "2020-05-12                    False                    False   \n",
            "2020-05-13                    False                    False   \n",
            "2020-05-14                    False                    False   \n",
            "2020-05-15                    False                    False   \n",
            "2020-05-16                    False                    False   \n",
            "\n",
            "            D1_lagging_span_lag_7  \n",
            "timestamp                          \n",
            "2020-05-12                  False  \n",
            "2020-05-13                  False  \n",
            "2020-05-14                  False  \n",
            "2020-05-15                  False  \n",
            "2020-05-16                  False  \n",
            "\n",
            "[5 rows x 133 columns]\n"
          ]
        }
      ],
      "source": [
        "print(d1_lags_focused.isnull().head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Aligning D1_lags data with H4 timestamps...\n",
            "✅ D1_lags data aligned: 133 features, 12368 records\n",
            "🔄 Aligning W1_lags data with H4 timestamps...\n",
            "✅ W1_lags data aligned: 72 features, 12368 records\n",
            "🔄 Aligning M1_lags data with H4 timestamps...\n",
            "✅ M1_lags data aligned: 24 features, 12368 records\n",
            "✅ A4 feature set created with temporal alignment:\n",
            "  A4: 411 features, 12368 records\n",
            "  - Current indicators: 68\n",
            "  - Historical lags: 343\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Create A4 Feature Set with Temporal Alignment (Using Full Data)\n",
        "def create_a4_features_with_temporal_alignment(A3, h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full):\n",
        "    \"\"\"Create A4 feature set: A3 + all historical lags with proper temporal alignment\"\"\"\n",
        "    \n",
        "    # Align D1, W1, M1 lag features with H4 timestamps\n",
        "    d1_lags_aligned = align_timeframe_data(A3, d1_lags_full, 'H4', 'D1_lags')\n",
        "    w1_lags_aligned = align_timeframe_data(A3, w1_lags_full, 'H4', 'W1_lags')\n",
        "    m1_lags_aligned = align_timeframe_data(A3, m1_lags_full, 'H4', 'M1_lags')\n",
        "    \n",
        "    # Combine A3 with all lag features\n",
        "    A4 = pd.concat([A3, h4_lags_full, d1_lags_aligned, w1_lags_aligned, m1_lags_aligned], axis=1)\n",
        "    \n",
        "    print(f\"✅ A4 feature set created with temporal alignment:\")\n",
        "    print(f\"  A4: {len(A4.columns)} features, {len(A4)} records\")\n",
        "    print(f\"  - Current indicators: {len(A3.columns)}\")\n",
        "    print(f\"  - Historical lags: {len(A4.columns) - len(A3.columns)}\")\n",
        "    \n",
        "    return A4\n",
        "\n",
        "# Create A4 feature set with temporal alignment\n",
        "A4 = create_a4_features_with_temporal_alignment(A3, h4_lags_full, d1_lags_full, w1_lags_full, m1_lags_full)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Feature Set Validation (Train/Test Period Only):\n",
            "📅 Period: 2020-05-12 to 2025-09-19\n",
            "🔍 Feature Set Validation:\n",
            "  ✅ A0: 19/19 features\n",
            "  ✅ A1: 38/38 features\n",
            "  ✅ A2: 56/56 features\n",
            "  ❌ A3: 68/67 features\n",
            "  ❌ A4: 411/416 features\n",
            "\n",
            "🔍 Missing Values Check (Train/Test Period Only):\n",
            "  A0: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A1: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A2: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A3: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n",
            "  A4: 0 missing values (0.00%)\n",
            "    Period: 2020-05-12 00:00:00 to 2025-09-19 00:00:00\n",
            "    Records: 11737\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Data Validation & Quality Checks\n",
        "def validate_feature_sets(A0,\n",
        "                          A1,\n",
        "                          A2,\n",
        "                          A3,\n",
        "                          A4,\n",
        "                          train_start='2020-05-12',\n",
        "                          test_end='2025-09-19'):\n",
        "    \"\"\"Validate all feature sets\"\"\"\n",
        "    print(\"🔍 Feature Set Validation (Train/Test Period Only):\")\n",
        "    print(f\"📅 Period: {train_start} to {test_end}\")\n",
        "\n",
        "    A0_focused = A0[(A0.index >= train_start) & (A0.index <= test_end)]\n",
        "    A1_focused = A1[(A1.index >= train_start) & (A1.index <= test_end)]\n",
        "    A2_focused = A2[(A2.index >= train_start) & (A2.index <= test_end)]\n",
        "    A3_focused = A3[(A3.index >= train_start) & (A3.index <= test_end)]\n",
        "    A4_focused = A4[(A4.index >= train_start) & (A4.index <= test_end)]\n",
        "\n",
        "    feature_counts = {\n",
        "        'A0': len(A0_focused.columns),\n",
        "        'A1': len(A1_focused.columns),\n",
        "        'A2': len(A2_focused.columns),\n",
        "        'A3': len(A3_focused.columns),\n",
        "        'A4': len(A4_focused.columns)\n",
        "    }\n",
        "\n",
        "    # A0 : 19, A1 : 38, A2 : 38 + 19 - 1= 56,  A3 : 56 + 19 - 4 = 71, A4 : \n",
        "    expected_counts = {'A0': 19, 'A1': 38, 'A2': 56, 'A3': 68, 'A4': 411}\n",
        "\n",
        "    print(\"🔍 Feature Set Validation:\")\n",
        "    for set_name, count in feature_counts.items():\n",
        "        expected = expected_counts[set_name]\n",
        "        status = \"✅\" if count == expected else \"❌\"\n",
        "        print(f\"  {status} {set_name}: {count}/{expected} features\")\n",
        "\n",
        "    # Check for missing values in focused period only\n",
        "    print(\"\\n🔍 Missing Values Check (Train/Test Period Only):\")\n",
        "    for set_name, features in [('A0', A0_focused), ('A1', A1_focused),\n",
        "                               ('A2', A2_focused), ('A3', A3_focused),\n",
        "                               ('A4', A4_focused)]:\n",
        "        missing_count = features.isnull().sum().sum()\n",
        "        total_cells = features.shape[0] * features.shape[1]\n",
        "        missing_percentage = (missing_count / total_cells) * 100\n",
        "        print(\n",
        "            f\"  {set_name}: {missing_count:,} missing values ({missing_percentage:.2f}%)\"\n",
        "        )\n",
        "        print(f\"    Period: {features.index[0]} to {features.index[-1]}\")\n",
        "        print(f\"    Records: {len(features)}\")\n",
        "\n",
        "    return feature_counts, (A0_focused, A1_focused, A2_focused, A3_focused,\n",
        "                            A4_focused)\n",
        "\n",
        "# Validate feature sets\n",
        "validation_results_focused, focused_sets = validate_feature_sets(A0, A1, A2, A3, A4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M1 data availability:\n",
            "First M1 timestamp: 2017-12-01 00:00:00\n",
            "Last M1 timestamp: 2025-10-01 00:00:00\n",
            "Total M1 records: 95\n",
            "M1 temporal alignment check:\n",
            "A3 missing values: 0\n",
            "A3 M1 columns missing: 0\n",
            "Lag feature missing values:\n",
            "A4 H4 lags missing: 0\n",
            "A4 D1 lags missing: 0\n",
            "A4 W1 lags missing: 0\n",
            "A4 M1 lags missing: 0\n"
          ]
        }
      ],
      "source": [
        "*_,A3_focused,A4_focused=focused_sets\n",
        "# Check when M1 data becomes available\n",
        "print(\"M1 data availability:\")\n",
        "print(f\"First M1 timestamp: {m1_indicators_clean.index[0]}\")\n",
        "print(f\"Last M1 timestamp: {m1_indicators_clean.index[-1]}\")\n",
        "print(f\"Total M1 records: {len(m1_indicators_clean)}\")\n",
        "\n",
        "\n",
        "# Check if M1 alignment is working correctly\n",
        "print(\"M1 temporal alignment check:\")\n",
        "print(f\"A3 missing values: {A3_focused.isnull().sum().sum()}\")\n",
        "print(\n",
        "    f\"A3 M1 columns missing: {A3_focused.filter(regex='M1_').isnull().sum().sum()}\"\n",
        ")\n",
        "\n",
        "# Check lag feature missing values\n",
        "print(\"Lag feature missing values:\")\n",
        "print(f\"A4 H4 lags missing: {A4_focused.filter(regex='H4_.*_lag_').isnull().sum().sum()}\")\n",
        "print(f\"A4 D1 lags missing: {A4_focused.filter(regex='D1_.*_lag_').isnull().sum().sum()}\")\n",
        "print(f\"A4 W1 lags missing: {A4_focused.filter(regex='W1_.*_lag_').isnull().sum().sum()}\")\n",
        "print(f\"A4 M1 lags missing: {A4_focused.filter(regex='M1_.*_lag_').isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Creating target variable (vectorized first threshold logic)...\n",
            "🔄 Calculating target labels...\n",
            "   Processing 0/12368 records...\n",
            "   Processing 1000/12368 records...\n",
            "   Processing 2000/12368 records...\n",
            "   Processing 3000/12368 records...\n",
            "   Processing 4000/12368 records...\n",
            "   Processing 5000/12368 records...\n",
            "   Processing 6000/12368 records...\n",
            "   Processing 7000/12368 records...\n",
            "   Processing 8000/12368 records...\n",
            "   Processing 9000/12368 records...\n",
            "   Processing 10000/12368 records...\n",
            "   Processing 11000/12368 records...\n",
            "   Processing 12000/12368 records...\n",
            "✅ Target variable created:\n",
            "   Total records: 11737\n",
            "   Sell labels: 2733\n",
            "   Rest labels: 9004\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-05-12 00:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 04:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 08:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 12:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-12 16:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 08:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 12:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 16:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-18 20:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-19 00:00:00</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11737 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     target\n",
              "timestamp                  \n",
              "2020-05-12 00:00:00       0\n",
              "2020-05-12 04:00:00       0\n",
              "2020-05-12 08:00:00       0\n",
              "2020-05-12 12:00:00       0\n",
              "2020-05-12 16:00:00       0\n",
              "...                     ...\n",
              "2025-09-18 08:00:00       0\n",
              "2025-09-18 12:00:00       0\n",
              "2025-09-18 16:00:00       0\n",
              "2025-09-18 20:00:00       0\n",
              "2025-09-19 00:00:00       0\n",
              "\n",
              "[11737 rows x 1 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_target_variable_first_threshold_vectorized(h4_full,\n",
        "                                                      train_start='2020-05-12',\n",
        "                                                      test_end='2025-09-19'):\n",
        "    \"\"\"\n",
        "    Create target variable using vectorized operations for efficiency\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🎯 Creating target variable (vectorized first threshold logic)...\")\n",
        "\n",
        "    # Create target variable for ALL H4 data\n",
        "    y_full = pd.DataFrame(index=h4_full.index)\n",
        "    y_full['target'] = 0  # Initialize with 0\n",
        "\n",
        "    print(\"🔄 Calculating target labels...\")\n",
        "\n",
        "    for i in range(len(h4_full)):\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"   Processing {i}/{len(h4_full)} records...\")\n",
        "\n",
        "        current_close = h4_full.iloc[i]['close']\n",
        "\n",
        "        # Get next 180 periods (30 days * 6 periods per day)\n",
        "        if i + 180 < len(h4_full):\n",
        "            future_data = h4_full.iloc[i + 1:i + 181]\n",
        "\n",
        "            # Calculate price changes\n",
        "            price_increases = (future_data['close'] - current_close) / current_close\n",
        "            price_drops = (future_data['low'] - current_close) / current_close\n",
        "\n",
        "            # Find first threshold and assign directly\n",
        "            for j in range(len(future_data)):\n",
        "                # Check +5% threshold first\n",
        "                if price_increases.iloc[j] >= 0.10:\n",
        "                    y_full.iloc[i, 0] = 0  # BUY first - assign and break\n",
        "                    break\n",
        "                \n",
        "                # Check -15% threshold\n",
        "                if price_drops.iloc[j] <= -0.15:\n",
        "                    y_full.iloc[i, 0] = 1  # SELL first - assign and break\n",
        "                    break\n",
        "            else:\n",
        "                # If loop completes without break, neither threshold reached\n",
        "                y_full.iloc[i, 0] = 0  # Default to REST\n",
        "\n",
        "                # Filter to focused period\n",
        "                y_focused = y_full[(y_full.index >= train_start)\n",
        "                                & (y_full.index <= test_end)]\n",
        "\n",
        "    print(f\"✅ Target variable created:\")\n",
        "    print(f\"   Total records: {len(y_focused)}\")\n",
        "    print(f\"   Sell labels: {y_focused['target'].sum()}\")\n",
        "    print(f\"   Rest labels: {len(y_focused) - y_focused['target'].sum()}\")\n",
        "\n",
        "    return y_focused\n",
        "\n",
        "create_target_variable_first_threshold_vectorized(h4_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Saving focused feature sets...\n",
            "🎯 Creating target variable (vectorized first threshold logic)...\n",
            "🔄 Calculating target labels...\n",
            "   Processing 0/12368 records...\n",
            "   Processing 1000/12368 records...\n",
            "   Processing 2000/12368 records...\n",
            "   Processing 3000/12368 records...\n",
            "   Processing 4000/12368 records...\n",
            "   Processing 5000/12368 records...\n",
            "   Processing 6000/12368 records...\n",
            "   Processing 7000/12368 records...\n",
            "   Processing 8000/12368 records...\n",
            "   Processing 9000/12368 records...\n",
            "   Processing 10000/12368 records...\n",
            "   Processing 11000/12368 records...\n",
            "   Processing 12000/12368 records...\n",
            "✅ Target variable created:\n",
            "   Total records: 11737\n",
            "   Sell labels: 9046\n",
            "   Rest labels: 2691\n",
            "🎉 All feature sets saved successfully!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(                       H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  H4_RSI_14  H4_MACD_line  H4_MACD_signal  \\\n",
              " timestamp                                                                     \n",
              " 2020-05-12 00:00:00    8496.361583  41.982660   -185.647639     -149.012220   \n",
              " 2020-05-12 04:00:00    8510.644417  40.692031   -185.576736     -156.325123   \n",
              " 2020-05-12 08:00:00    8526.020417  45.080613   -171.849769     -159.430052   \n",
              " 2020-05-12 12:00:00    8540.649750  47.027084   -153.807846     -158.305611   \n",
              " 2020-05-12 16:00:00    8554.871583  45.081508   -143.944825     -155.433454   \n",
              " ...                            ...        ...           ...             ...   \n",
              " 2025-09-18 08:00:00  112520.355583  58.601589    483.262045      424.949027   \n",
              " 2025-09-18 12:00:00  112597.000000  61.876712    530.800011      446.119224   \n",
              " 2025-09-18 16:00:00  112673.985000  60.554112    551.358246      467.167028   \n",
              " 2025-09-18 20:00:00  112746.452750  56.857108    531.133293      479.960281   \n",
              " 2025-09-19 00:00:00  112817.630917  55.920549    501.580601      484.284345   \n",
              " \n",
              "                      H4_MACD_hist  H4_conversion_line  H4_baseline  \\\n",
              " timestamp                                                            \n",
              " 2020-05-12 00:00:00    -36.635420            8684.000      9092.00   \n",
              " 2020-05-12 04:00:00    -29.251613            8684.000      9076.48   \n",
              " 2020-05-12 08:00:00    -12.419717            8684.000      9061.99   \n",
              " 2020-05-12 12:00:00      4.497765            8684.000      9061.99   \n",
              " 2020-05-12 16:00:00     11.488629            8684.000      9061.99   \n",
              " ...                           ...                 ...          ...   \n",
              " 2025-09-18 08:00:00     58.313018          116308.405    116140.00   \n",
              " 2025-09-18 12:00:00     84.680787          116308.405    116140.00   \n",
              " 2025-09-18 16:00:00     84.191218          116310.405    116142.00   \n",
              " 2025-09-18 20:00:00     51.173012          116310.405    116142.00   \n",
              " 2025-09-19 00:00:00     17.296256          116310.405    116142.00   \n",
              " \n",
              "                      H4_leading_span_A  H4_leading_span_B  H4_lagging_span  \n",
              " timestamp                                                                   \n",
              " 2020-05-12 00:00:00          8888.0000           9092.000          9863.93  \n",
              " 2020-05-12 04:00:00          8880.2400           9092.000          9986.40  \n",
              " 2020-05-12 08:00:00          8872.9950           9092.000          9930.69  \n",
              " 2020-05-12 12:00:00          8872.9950           9092.000          9810.14  \n",
              " 2020-05-12 16:00:00          8872.9950           9092.000          9899.75  \n",
              " ...                                ...                ...              ...  \n",
              " 2025-09-18 08:00:00        116224.2025         114406.725        115679.98  \n",
              " 2025-09-18 12:00:00        116224.2025         114406.725        115805.39  \n",
              " 2025-09-18 16:00:00        116226.2025         114636.210        115794.91  \n",
              " 2025-09-18 20:00:00        116226.2025         114998.600        115224.01  \n",
              " 2025-09-19 00:00:00        116226.2025         115099.995        115634.99  \n",
              " \n",
              " [11737 rows x 19 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...      D1_MA_120  D1_RSI_14  \\\n",
              " timestamp                           ...                             \n",
              " 2020-05-12 00:00:00    8496.361583  ...    8134.400833  52.874315   \n",
              " 2020-05-12 04:00:00    8510.644417  ...    8134.400833  52.874315   \n",
              " 2020-05-12 08:00:00    8526.020417  ...    8134.400833  52.874315   \n",
              " 2020-05-12 12:00:00    8540.649750  ...    8134.400833  52.874315   \n",
              " 2020-05-12 16:00:00    8554.871583  ...    8134.400833  52.874315   \n",
              " ...                            ...  ...            ...        ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...  111815.687833    59.4072   \n",
              " 2025-09-18 12:00:00  112597.000000  ...  111815.687833    59.4072   \n",
              " 2025-09-18 16:00:00  112673.985000  ...  111815.687833    59.4072   \n",
              " 2025-09-18 20:00:00  112746.452750  ...  111815.687833    59.4072   \n",
              " 2025-09-19 00:00:00  112817.630917  ...  111877.600667  61.177934   \n",
              " \n",
              "                      D1_MACD_line  D1_MACD_signal  D1_MACD_hist  \\\n",
              " timestamp                                                         \n",
              " 2020-05-12 00:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 04:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 08:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 12:00:00    515.398008       544.23139    -28.833382   \n",
              " 2020-05-12 16:00:00    515.398008       544.23139    -28.833382   \n",
              " ...                           ...             ...           ...   \n",
              " 2025-09-18 08:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-18 12:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-18 16:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-18 20:00:00    771.995691       87.595779    684.399912   \n",
              " 2025-09-19 00:00:00    908.385644      251.753752    656.631892   \n",
              " \n",
              "                      D1_conversion_line  D1_baseline  D1_leading_span_A  \\\n",
              " timestamp                                                                 \n",
              " 2020-05-12 00:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 04:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 08:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 12:00:00              9092.0     8267.635          8679.8175   \n",
              " 2020-05-12 16:00:00              9092.0     8267.635          8679.8175   \n",
              " ...                                 ...          ...                ...   \n",
              " 2025-09-18 08:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-18 12:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-18 16:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-18 20:00:00          114026.695   112270.865          113148.78   \n",
              " 2025-09-19 00:00:00          114408.725     112577.5        113493.1125   \n",
              " \n",
              "                      D1_leading_span_B D1_lagging_span  \n",
              " timestamp                                               \n",
              " 2020-05-12 00:00:00             7877.5         6621.24  \n",
              " 2020-05-12 04:00:00             7877.5         6621.24  \n",
              " 2020-05-12 08:00:00             7877.5         6621.24  \n",
              " 2020-05-12 12:00:00             7877.5         6621.24  \n",
              " 2020-05-12 16:00:00             7877.5         6621.24  \n",
              " ...                                ...             ...  \n",
              " 2025-09-18 08:00:00           115864.5       116935.99  \n",
              " 2025-09-18 12:00:00           115864.5       116935.99  \n",
              " 2025-09-18 16:00:00           115864.5       116935.99  \n",
              " 2025-09-18 20:00:00           115864.5       116935.99  \n",
              " 2025-09-19 00:00:00           115864.5       115438.05  \n",
              " \n",
              " [11737 rows x 38 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...      W1_MA_60  W1_RSI_14  \\\n",
              " timestamp                           ...                            \n",
              " 2020-05-12 00:00:00    8496.361583  ...   8250.270333  55.285125   \n",
              " 2020-05-12 04:00:00    8510.644417  ...   8250.270333  55.285125   \n",
              " 2020-05-12 08:00:00    8526.020417  ...   8250.270333  55.285125   \n",
              " 2020-05-12 12:00:00    8540.649750  ...   8250.270333  55.285125   \n",
              " 2020-05-12 16:00:00    8554.871583  ...   8250.270333  55.285125   \n",
              " ...                            ...  ...           ...        ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...  90905.399667  59.230544   \n",
              " 2025-09-18 12:00:00  112597.000000  ...  90905.399667  59.230544   \n",
              " 2025-09-18 16:00:00  112673.985000  ...  90905.399667  59.230544   \n",
              " 2025-09-18 20:00:00  112746.452750  ...  90905.399667  59.230544   \n",
              " 2025-09-19 00:00:00  112817.630917  ...  90905.399667  59.230544   \n",
              " \n",
              "                      W1_MACD_line  W1_MACD_signal  W1_MACD_hist  \\\n",
              " timestamp                                                         \n",
              " 2020-05-12 00:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 04:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 08:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 12:00:00   -100.083928      -197.59971     97.515782   \n",
              " 2020-05-12 16:00:00   -100.083928      -197.59971     97.515782   \n",
              " ...                           ...             ...           ...   \n",
              " 2025-09-18 08:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-18 12:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-18 16:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-18 20:00:00   5766.790835     6532.774439   -765.983604   \n",
              " 2025-09-19 00:00:00   5766.790835     6532.774439   -765.983604   \n",
              " \n",
              "                      W1_conversion_line  W1_baseline  W1_leading_span_A  \\\n",
              " timestamp                                                                 \n",
              " 2020-05-12 00:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 04:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 08:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 12:00:00            6924.565     7141.065           7032.815   \n",
              " 2020-05-12 16:00:00            6924.565     7141.065           7032.815   \n",
              " ...                                 ...          ...                ...   \n",
              " 2025-09-18 08:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-18 12:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-18 16:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-18 20:00:00            115864.5      99491.0          107677.75   \n",
              " 2025-09-19 00:00:00            115864.5      99491.0          107677.75   \n",
              " \n",
              "                      W1_leading_span_B W1_lagging_span  \n",
              " timestamp                                               \n",
              " 2020-05-12 00:00:00           8876.065         9039.47  \n",
              " 2020-05-12 04:00:00           8876.065         9039.47  \n",
              " 2020-05-12 08:00:00           8876.065         9039.47  \n",
              " 2020-05-12 12:00:00           8876.065         9039.47  \n",
              " 2020-05-12 16:00:00           8876.065         9039.47  \n",
              " ...                                ...             ...  \n",
              " 2025-09-18 08:00:00           90983.65        82574.53  \n",
              " 2025-09-18 12:00:00           90983.65        82574.53  \n",
              " 2025-09-18 16:00:00           90983.65        82574.53  \n",
              " 2025-09-18 20:00:00           90983.65        82574.53  \n",
              " 2025-09-19 00:00:00           90983.65        82574.53  \n",
              " \n",
              " [11737 rows x 56 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...    M1_low   M1_close       M1_volume  \\\n",
              " timestamp                           ...                                        \n",
              " 2020-05-12 00:00:00    8496.361583  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 04:00:00    8510.644417  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 08:00:00    8526.020417  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 12:00:00    8540.649750  ...   6150.11     8620.0  2528373.691121   \n",
              " 2020-05-12 16:00:00    8554.871583  ...   6150.11     8620.0  2528373.691121   \n",
              " ...                            ...  ...       ...        ...             ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-18 12:00:00  112597.000000  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-18 16:00:00  112673.985000  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-18 20:00:00  112746.452750  ...  107350.1  108246.35   471366.942936   \n",
              " 2025-09-19 00:00:00  112817.630917  ...  107350.1  108246.35   471366.942936   \n",
              " \n",
              "                           M1_MA_7      M1_MA_14    M1_MA_20  M1_RSI_14  \\\n",
              " timestamp                                                                \n",
              " 2020-05-12 00:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 04:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 08:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 12:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " 2020-05-12 16:00:00       8112.13   8112.579286    7078.331  46.490214   \n",
              " ...                           ...           ...         ...        ...   \n",
              " 2025-09-18 08:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-18 12:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-18 16:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-18 20:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " 2025-09-19 00:00:00  99545.822857  89032.564286  80621.5455  67.262225   \n",
              " \n",
              "                      M1_conversion_line  M1_baseline M1_lagging_span  \n",
              " timestamp                                                             \n",
              " 2020-05-12 00:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 04:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 08:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 12:00:00            8056.415      8563.13        10326.76  \n",
              " 2020-05-12 16:00:00            8056.415      8563.13        10326.76  \n",
              " ...                                 ...          ...             ...  \n",
              " 2025-09-18 08:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-18 12:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-18 16:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-18 20:00:00             99491.0      74687.5         30472.0  \n",
              " 2025-09-19 00:00:00             99491.0      74687.5         30472.0  \n",
              " \n",
              " [11737 rows x 68 columns],\n",
              "                        H4_open    H4_high     H4_low   H4_close     H4_volume  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8562.04    8742.43    8528.78    8716.07  11224.925222   \n",
              " 2020-05-12 04:00:00    8716.75    8785.00    8614.98    8656.05  10948.791761   \n",
              " 2020-05-12 08:00:00    8655.76    8828.72    8632.93    8800.92  14846.694767   \n",
              " 2020-05-12 12:00:00    8800.91    8944.72    8659.00    8867.72  22551.312510   \n",
              " 2020-05-12 16:00:00    8867.72    8978.26    8775.00    8792.19  17005.945766   \n",
              " ...                        ...        ...        ...        ...           ...   \n",
              " 2025-09-18 08:00:00  117086.01  117413.04  117010.59  117063.40   1165.752290   \n",
              " 2025-09-18 12:00:00  117063.41  117843.83  116977.59  117583.56   2416.331940   \n",
              " 2025-09-18 16:00:00  117583.56  117900.00  117196.33  117450.21   1828.623500   \n",
              " 2025-09-18 20:00:00  117450.21  117657.17  116612.03  117073.53   1375.217250   \n",
              " 2025-09-19 00:00:00  117073.53  117459.99  116871.61  116977.58   1326.387840   \n",
              " \n",
              "                            H4_MA_7       H4_MA_14     H4_MA_20       H4_MA_60  \\\n",
              " timestamp                                                                       \n",
              " 2020-05-12 00:00:00    8742.257143    8770.305714    9055.6160    9118.310833   \n",
              " 2020-05-12 04:00:00    8736.458571    8707.209286    8998.4180    9115.928167   \n",
              " 2020-05-12 08:00:00    8755.972857    8719.933571    8945.3130    9115.376833   \n",
              " 2020-05-12 12:00:00    8747.442857    8723.893571    8909.0605    9114.232000   \n",
              " 2020-05-12 16:00:00    8734.475714    8727.810714    8866.7275    9112.800000   \n",
              " ...                            ...            ...          ...            ...   \n",
              " 2025-09-18 08:00:00  116566.304286  116437.245714  116090.2850  114847.333667   \n",
              " 2025-09-18 12:00:00  116755.651429  116561.785714  116179.1320  114929.863833   \n",
              " 2025-09-18 16:00:00  116980.635714  116716.241429  116298.1425  115019.078833   \n",
              " 2025-09-18 20:00:00  117183.708571  116799.645000  116409.6740  115102.550500   \n",
              " 2025-09-19 00:00:00  117259.421429  116812.320714  116493.1640  115190.376833   \n",
              " \n",
              "                          H4_MA_120  ...  M1_low_lag_2  M1_close_lag_2  \\\n",
              " timestamp                           ...                                 \n",
              " 2020-05-12 00:00:00    8496.361583  ...        8445.0         8523.61   \n",
              " 2020-05-12 04:00:00    8510.644417  ...        8445.0         8523.61   \n",
              " 2020-05-12 08:00:00    8526.020417  ...        8445.0         8523.61   \n",
              " 2020-05-12 12:00:00    8540.649750  ...        8445.0         8523.61   \n",
              " 2020-05-12 16:00:00    8554.871583  ...        8445.0         8523.61   \n",
              " ...                            ...  ...           ...             ...   \n",
              " 2025-09-18 08:00:00  112520.355583  ...       98200.0        107146.5   \n",
              " 2025-09-18 12:00:00  112597.000000  ...       98200.0        107146.5   \n",
              " 2025-09-18 16:00:00  112673.985000  ...       98200.0        107146.5   \n",
              " 2025-09-18 20:00:00  112746.452750  ...       98200.0        107146.5   \n",
              " 2025-09-19 00:00:00  112817.630917  ...       98200.0        107146.5   \n",
              " \n",
              "                      M1_volume_lag_2  M1_MA_7_lag_2  M1_MA_14_lag_2  \\\n",
              " timestamp                                                             \n",
              " 2020-05-12 00:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 04:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 08:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 12:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " 2020-05-12 16:00:00   1609726.154564    8518.754286     7556.675714   \n",
              " ...                              ...            ...             ...   \n",
              " 2025-09-18 08:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-18 12:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-18 16:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-18 20:00:00     427546.46336   95545.127143    82339.820714   \n",
              " 2025-09-19 00:00:00     427546.46336   95545.127143    82339.820714   \n",
              " \n",
              "                      M1_MA_20_lag_2  M1_RSI_14_lag_2  \\\n",
              " timestamp                                              \n",
              " 2020-05-12 00:00:00        7063.916        44.728795   \n",
              " 2020-05-12 04:00:00        7063.916        44.728795   \n",
              " 2020-05-12 08:00:00        7063.916        44.728795   \n",
              " 2020-05-12 12:00:00        7063.916        44.728795   \n",
              " 2020-05-12 16:00:00        7063.916        44.728795   \n",
              " ...                             ...              ...   \n",
              " 2025-09-18 08:00:00       73421.401        70.031673   \n",
              " 2025-09-18 12:00:00       73421.401        70.031673   \n",
              " 2025-09-18 16:00:00       73421.401        70.031673   \n",
              " 2025-09-18 20:00:00       73421.401        70.031673   \n",
              " 2025-09-19 00:00:00       73421.401        70.031673   \n",
              " \n",
              "                      M1_conversion_line_lag_2  M1_baseline_lag_2  \\\n",
              " timestamp                                                          \n",
              " 2020-05-12 00:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 04:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 08:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 12:00:00                   10202.5           10166.25   \n",
              " 2020-05-12 16:00:00                   10202.5           10166.25   \n",
              " ...                                       ...                ...   \n",
              " 2025-09-18 08:00:00                   85463.0            68390.0   \n",
              " 2025-09-18 12:00:00                   85463.0            68390.0   \n",
              " 2025-09-18 16:00:00                   85463.0            68390.0   \n",
              " 2025-09-18 20:00:00                   85463.0            68390.0   \n",
              " 2025-09-19 00:00:00                   85463.0            68390.0   \n",
              " \n",
              "                     M1_lagging_span_lag_2  \n",
              " timestamp                                  \n",
              " 2020-05-12 00:00:00              13716.36  \n",
              " 2020-05-12 04:00:00              13716.36  \n",
              " 2020-05-12 08:00:00              13716.36  \n",
              " 2020-05-12 12:00:00              13716.36  \n",
              " 2020-05-12 16:00:00              13716.36  \n",
              " ...                                   ...  \n",
              " 2025-09-18 08:00:00              29233.21  \n",
              " 2025-09-18 12:00:00              29233.21  \n",
              " 2025-09-18 16:00:00              29233.21  \n",
              " 2025-09-18 20:00:00              29233.21  \n",
              " 2025-09-19 00:00:00              29233.21  \n",
              " \n",
              " [11737 rows x 411 columns],\n",
              "                      target\n",
              " timestamp                  \n",
              " 2020-05-12 00:00:00       1\n",
              " 2020-05-12 04:00:00       1\n",
              " 2020-05-12 08:00:00       1\n",
              " 2020-05-12 12:00:00       1\n",
              " 2020-05-12 16:00:00       1\n",
              " ...                     ...\n",
              " 2025-09-18 08:00:00       1\n",
              " 2025-09-18 12:00:00       1\n",
              " 2025-09-18 16:00:00       1\n",
              " 2025-09-18 20:00:00       1\n",
              " 2025-09-19 00:00:00       1\n",
              " \n",
              " [11737 rows x 1 columns])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def save_focused_feature_sets_complete(A0, A1, A2, A3, A4, h4_full, train_start='2020-05-12', test_end='2025-09-19'):\n",
        "    \"\"\"Save focused feature sets with correct target variable creation\"\"\"\n",
        "    \n",
        "    print(\"💾 Saving focused feature sets...\")\n",
        "    \n",
        "    # Create features directory\n",
        "    features_dir = Path('../features')\n",
        "    features_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Filter feature sets to focused period\n",
        "    def filter_focused_period(data, start_date, end_date):\n",
        "        return data[(data.index >= start_date) & (data.index <= end_date)]\n",
        "    \n",
        "    # Save feature sets\n",
        "    A0_focused = filter_focused_period(A0, train_start, test_end)\n",
        "    A1_focused = filter_focused_period(A1, train_start, test_end)\n",
        "    A2_focused = filter_focused_period(A2, train_start, test_end)\n",
        "    A3_focused = filter_focused_period(A3, train_start, test_end)\n",
        "    A4_focused = filter_focused_period(A4, train_start, test_end)\n",
        "    \n",
        "    # Create target variable using FULL H4 data\n",
        "    y_focused = create_target_variable_first_threshold_vectorized(h4_full, train_start, test_end)\n",
        "    \n",
        "    # Save all files\n",
        "    A0_focused.to_parquet(features_dir / 'A0.parquet')\n",
        "    A1_focused.to_parquet(features_dir / 'A1.parquet')\n",
        "    A2_focused.to_parquet(features_dir / 'A2.parquet')\n",
        "    A3_focused.to_parquet(features_dir / 'A3.parquet')\n",
        "    A4_focused.to_parquet(features_dir / 'A4.parquet')\n",
        "    y_focused.to_parquet(features_dir / 'y.parquet')\n",
        "    \n",
        "    print(\"🎉 All feature sets saved successfully!\")\n",
        "    return A0_focused, A1_focused, A2_focused, A3_focused, A4_focused, y_focused\n",
        "\n",
        "# Run the complete save function\n",
        "save_focused_feature_sets_complete(A0, A1, A2, A3, A4, h4_full, train_start='2020-05-12', test_end='2025-09-19')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_saved_feature_sets(features_dir='../features'):\n",
        "    \"\"\"\n",
        "    Validate that all feature sets and target variable were saved correctly\n",
        "    \n",
        "    Args:\n",
        "        features_dir: Path to features directory\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"🔍 Validating Saved Feature Sets...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check if features directory exists\n",
        "    features_path = Path(features_dir)\n",
        "    if not features_path.exists():\n",
        "        print(\"❌ Features directory not found!\")\n",
        "        return\n",
        "    \n",
        "    # Expected files\n",
        "    expected_files = ['A0.parquet', 'A1.parquet', 'A2.parquet', 'A3.parquet', 'A4.parquet', 'y.parquet']\n",
        "    \n",
        "    print(\"📁 File Existence Check:\")\n",
        "    for file in expected_files:\n",
        "        file_path = features_path / file\n",
        "        if file_path.exists():\n",
        "            print(f\"  ✅ {file} - Found\")\n",
        "        else:\n",
        "            print(f\"  ❌ {file} - Missing!\")\n",
        "    \n",
        "    print(\"\\n📊 Data Validation:\")\n",
        "    \n",
        "    # Load and validate each file\n",
        "    for file in expected_files:\n",
        "        file_path = features_path / file\n",
        "        if not file_path.exists():\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\n🔍 Validating {file}:\")\n",
        "        \n",
        "        try:\n",
        "            # Load data\n",
        "            data = pd.read_parquet(file_path)\n",
        "            \n",
        "            # Basic info\n",
        "            print(f\"  📏 Shape: {data.shape[0]} records × {data.shape[1]} features\")\n",
        "            print(f\"  📅 Period: {data.index[0]} to {data.index[-1]}\")\n",
        "            \n",
        "            # Check for missing values\n",
        "            missing_count = data.isnull().sum().sum()\n",
        "            total_cells = data.shape[0] * data.shape[1]\n",
        "            missing_percentage = (missing_count / total_cells) * 100 if total_cells > 0 else 0\n",
        "            \n",
        "            if missing_count == 0:\n",
        "                print(f\"  ✅ Missing values: {missing_count} (0.00%)\")\n",
        "            else:\n",
        "                print(f\"  ⚠️ Missing values: {missing_count} ({missing_percentage:.2f}%)\")\n",
        "                \n",
        "                # Show which columns have missing values\n",
        "                missing_cols = data.isnull().sum()\n",
        "                missing_cols = missing_cols[missing_cols > 0]\n",
        "                if len(missing_cols) > 0:\n",
        "                    print(f\"    Columns with missing values:\")\n",
        "                    for col, count in missing_cols.items():\n",
        "                        print(f\"      {col}: {count} missing\")\n",
        "            \n",
        "            # Check data types\n",
        "            print(f\"  📋 Data types: {data.dtypes.value_counts().to_dict()}\")\n",
        "            \n",
        "            # Check for infinite values\n",
        "            inf_count = np.isinf(data.select_dtypes(include=[np.number])).sum().sum()\n",
        "            if inf_count == 0:\n",
        "                print(f\"  ✅ Infinite values: {inf_count}\")\n",
        "            else:\n",
        "                print(f\"  ⚠️ Infinite values: {inf_count}\")\n",
        "            \n",
        "            # Specific validation for target variable\n",
        "            if file == 'y.parquet':\n",
        "                print(f\"  🎯 Target variable validation:\")\n",
        "                print(f\"    Unique values: {data['target'].unique()}\")\n",
        "                print(f\"    Value counts: {data['target'].value_counts().to_dict()}\")\n",
        "                print(f\"    Sell percentage: {data['target'].mean()*100:.2f}%\")\n",
        "            \n",
        "            # Specific validation for feature sets\n",
        "            if file.startswith('A'):\n",
        "                print(f\"  🔢 Feature set validation:\")\n",
        "                print(f\"    Feature count: {len(data.columns)}\")\n",
        "                print(f\"    Sample features: {list(data.columns[:5])}\")\n",
        "                \n",
        "                # Check for expected feature counts\n",
        "                expected_counts = {'A0': 19, 'A1': 38, 'A2': 56, 'A3': 67, 'A4': 416}\n",
        "                if file.replace('.parquet', '') in expected_counts:\n",
        "                    expected = expected_counts[file.replace('.parquet', '')]\n",
        "                    actual = len(data.columns)\n",
        "                    if actual == expected:\n",
        "                        print(f\"    ✅ Feature count matches expected: {actual}\")\n",
        "                    else:\n",
        "                        print(f\"    ⚠️ Feature count mismatch: {actual} (expected {expected})\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Error loading {file}: {e}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"🎉 Validation Complete!\")\n",
        "\n",
        "# Run validation\n",
        "validate_saved_feature_sets('../features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.2 Implementation Complete! ✅\n",
        "\n",
        "### **Summary of CORRECTED Implementation**\n",
        "\n",
        "**Approach**: Calculate everything together, split on save step.\n",
        "\n",
        "**Steps Completed**:\n",
        "1. ✅ **Load Full Data**: Complete dataset including buffer (2020-03-01 to 2025-10-19)\n",
        "2. ✅ **Technical Indicators**: Calculated all 19 indicators per timeframe on full data\n",
        "3. ✅ **Feature Sets A0→A3**: Created incremental feature sets with proper temporal alignment\n",
        "4. ✅ **Historical Lag Features**: Created lag features using full data for complete historical context\n",
        "5. ✅ **A4 Feature Set**: Combined A3 + all historical lags (437 features)\n",
        "6. ✅ **Data Validation**: Verified feature counts and missing values\n",
        "7. ✅ **Save Clean Data**: Split clean period (2020-05-12 to 2025-09-19) only at save step\n",
        "\n",
        "### **Key Fixes Applied**:\n",
        "1. **Full Data Calculations**: All indicators and lags calculated on complete dataset\n",
        "2. **Proper Temporal Alignment**: Enhanced alignment logic with timeframe-specific offsets\n",
        "3. **Complete Historical Context**: W1 data from 2020-05-04, M1 data from 2020-05-01\n",
        "4. **No Missing Data**: Full historical context for all lag features\n",
        "5. **Clean Final Output**: Buffer data used for calculations but not stored\n",
        "\n",
        "### **Temporal Alignment Logic**:\n",
        "- **H4 timestamp 2020-05-11 00:00:00** (candle closed at 2020-05-11 04:00:00):\n",
        "  - **D1 data**: `base_timestamp - 1d` → Use 2020-05-10 00:00:00 (previous day's close) ✅\n",
        "  - **W1 data**: `base_timestamp - 1w` → Use 2020-05-04 00:00:00 (previous week's close) ✅\n",
        "  - **M1 data**: `base_timestamp - 1m` → Use 2020-04-11 00:00:00 (previous month's close) ✅\n",
        "- **Uses timeframe-specific offsets** to ensure proper temporal alignment\n",
        "- **Ensures no future data leakage** and realistic trading scenarios\n",
        "\n",
        "### **Expected Outputs**\n",
        "- **A0.parquet**: 19 features (H4 only)\n",
        "- **A1.parquet**: 38 features (H4 + D1)\n",
        "- **A2.parquet**: 57 features (H4 + D1 + W1)\n",
        "- **A3.parquet**: 76 features (H4 + D1 + W1 + M1)\n",
        "- **A4.parquet**: 437 features (A3 + all historical lags)\n",
        "\n",
        "### **Next Steps**\n",
        "- **Step 3**: Train/test split based on timeline\n",
        "- **Step 4**: Ablation Study experiments (A0→A4_Pruned)\n",
        "- **Step 5**: Results analysis and RQ answers\n",
        "\n",
        "**Ready to proceed to Step 3!** 🚀\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "csml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
